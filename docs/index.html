<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Análisis de Derrames de Agua Producida en Texas (2013-2022)</title>
    <style>
      body {
        font-family: "Inter", sans-serif;
        background-color: #f8fafc;
      }
      .nav-link {
        transition: all 0.2s ease-in-out;
        border-left: 3px solid transparent;
      }
      .nav-link.active {
        border-left-color: #3b82f6;
        color: #3b82f6;
        background-color: #eff6ff;
      }
      .chart-container {
        position: relative;
        width: 100%;
        height: 350px;
        max-height: 40vh;
      }
      @media (min-width: 768px) {
        .chart-container {
          height: 400px;
        }
      }
      .stat-card {
        background-color: white;
        border-radius: 0.75rem;
        padding: 1.5rem;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1),
          0 2px 4px -2px rgba(0, 0, 0, 0.1);
        transition: transform 0.2s ease-in-out;
      }
      .stat-card:hover {
        transform: translateY(-5px);
      }
      .method-step {
        position: relative;
        padding-left: 2.5rem;
        padding-bottom: 2rem;
        border-left: 2px solid #e5e7eb;
      }
      .method-step:last-child {
        border-left: 2px solid transparent;
        padding-bottom: 0;
      }
      .method-icon {
        position: absolute;
        left: -1rem;
        top: 0;
        width: 2rem;
        height: 2rem;
        display: flex;
        align-items: center;
        justify-content: center;
        border-radius: 9999px;
        background-color: white;
        border: 2px solid #e5e7eb;
      }
      .form-group {
        margin-bottom: 1.5rem;
      }
      .form-group label {
        display: block;
        margin-bottom: 0.5rem;
        font-weight: 500;
        color: #374151;
      }
      .form-group input,
      .form-group select {
        width: 100%;
        padding: 0.75rem;
        border: 1px solid #d1d5db;
        border-radius: 0.375rem;
        font-size: 1rem;
        transition: border-color 0.2s ease-in-out;
      }
      .form-group input:focus,
      .form-group select:focus {
        outline: none;
        border-color: #3b82f6;
        box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.1);
      }
      .predict-btn {
        background-color: #3b82f6;
        color: white;
        padding: 0.75rem 2rem;
        border: none;
        border-radius: 0.375rem;
        font-size: 1rem;
        font-weight: 500;
        cursor: pointer;
        transition: background-color 0.2s ease-in-out;
      }
      .predict-btn:hover {
        background-color: #2563eb;
      }
      .predict-btn:disabled {
        background-color: #9ca3af;
        cursor: not-allowed;
      }
      .result-card {
        background-color: #f0f9ff;
        border: 1px solid #0ea5e9;
        border-radius: 0.75rem;
        padding: 1.5rem;
        margin-top: 1.5rem;
      }
      .sidebar {
        background-color: #ffffff;
        box-shadow: 2px 0 10px rgba(0, 0, 0, 0.1);
      }
      .main-content {
        background-color: #f8fafc;
      }
      .section-title {
        color: #1e293b;
      }
      .section-content {
        color: #475569;
      }
      .data-table {
        width: 100%;
        border-collapse: collapse;
        margin: 1.5rem 0;
        background-color: white;
        border-radius: 0.5rem;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
      }
      .data-table th,
      .data-table td {
        padding: 0.75rem;
        text-align: left;
        border-bottom: 1px solid #e5e7eb;
      }
      .data-table th {
        background-color: #f8fafc;
        font-weight: 600;
        color: #374151;
      }
      .data-table tr:hover {
        background-color: #f9fafb;
      }
      .figure {
        margin: 2rem 0;
        padding: 1rem;
        background-color: white;
        border-radius: 0.5rem;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
      }
      .figure p {
        font-style: italic;
        color: #6b7280;
        margin-bottom: 0.5rem;
      }
      #chartContainer {
        max-width: auto;           
        margin: auto;
        display: flex;
        justify-content: center;
      }

        #performanceChart {
        display: block;
        margin: auto;
        width: 600px;
        max-width: 1000px;
        height: auto !important;
         }

   
        body { font-family: Arial, sans-serif; margin: 20px; }
        nav { background-color: #f8f8f8; padding: 10px; }
        nav ul { list-style-type: none; padding: 0; }
        nav ul li { display: inline; margin-right: 10px; }
        nav ul li a { text-decoration: none; color: #333; }
        section { margin-bottom: 20px; }
        h1, h2, h3 { color: #333; }
        table { border-collapse: collapse; width: 100%; }
        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
        th { background-color: #f2f2f2; }
        img { max-width: 100%; height: auto; }
        .math { font-style: italic; }
    </style>
</head>
<body>
    <nav>
        <h2>Menú del Informe</h2>
        <ul>
            <li><a href="#machine-learning">Entendiendo Machine Learning</a></li>
            <li><a href="#problema">Problema</a></li>
            <li><a href="#introduccion">Introducción</a></li>
            <li><a href="#objetivos">Objetivos</a></li>
            <li><a href="#resumen">Resumen y Métricas</a></li>
            <li><a href="#metodologia">Metodología</a></li>
            <li><a href="#experimentacion">Experimentación</a></li>
            <li><a href="#resultados">Resultados Clave</a></li>
            <li><a href="#rendimiento">Rendimiento</a></li>
            <li><a href="#discusion">Discusión</a></li>
            <li><a href="#predicciones">Predicciones</a></li>
            <li><a href="#aplicacion">Aplicación Web</a></li>
            <li><a href="#conclusiones">Conclusiones</a></li>
        </ul>
    </nav>

    <header>
        <h1>Análisis de Derrames de Agua Producida en Texas (2013-2022)</h1>
        <h2>Un Vistazo Interactivo al Modelo Multitarea</h2>
    </header>

    <section id="machine-learning">
        <h2>Entendiendo Machine Learning</h2>
        <p>El aprendizaje automático (<em>machine learning</em>) es una rama de la inteligencia artificial que permite a los sistemas aprender patrones a partir de datos sin ser explícitamente programados. En este proyecto, utilizamos técnicas de aprendizaje automático, específicamente regresión lineal y conceptos relacionados, para analizar los derrames de agua producida. A continuación, se explican los fundamentos teóricos clave para comprender el enfoque utilizado.</p>

        <h3>Regresión Lineal</h3>
        <p>La regresión lineal es una técnica estadística utilizada para modelar la relación entre una variable dependiente (etiqueta) y una o más variables independientes (características). En el contexto del aprendizaje automático, se utiliza para predecir valores numéricos continuos.</p>
        <p>Por ejemplo, supongamos que queremos predecir la eficiencia de combustible de un automóvil (millas por galón) basándonos en su peso (en miles de libras). A continuación, se muestra un conjunto de datos de ejemplo:</p>
        <table>
            <tr><th>Peso (miles de libras)</th><th>Millas por galón</th></tr>
            <tr><td>3.5</td><td>18</td></tr>
            <tr><td>3.69</td><td>15</td></tr>
            <tr><td>3.44</td><td>18</td></tr>
            <tr><td>3.43</td><td>16</td></tr>
            <tr><td>4.34</td><td>15</td></tr>
            <tr><td>4.42</td><td>14</td></tr>
            <tr><td>2.37</td><td>24</td></tr>
        </table>
        <p>Figura 1: Gráfico de puntos que muestra una tendencia descendente de izquierda a derecha, donde a mayor peso, menor eficiencia de combustible.</p>
        <img src="placeholder_car_data.png" alt="Peso vs. Eficiencia de combustible">

        <h4>Ecuación de la Regresión Lineal</h4>
        <p>La regresión lineal modela la relación entre las variables mediante una línea recta, definida por la ecuación:</p>
        <p class="math">y = mx + b</p>
        <p>Donde:</p>
        <ul>
            <li><span class="math">y</span>: es la variable dependiente (etiqueta, en este caso, millas por galón).</li>
            <li><span class="math">m</span>: es la pendiente de la línea, que representa el cambio en <span class="math">y</span> por cada unidad de cambio en <span class="math">x</span>.</li>
            <li><span class="math">x</span>: es la variable independiente (característica, en este caso, peso).</li>
            <li><span class="math">b</span>: es la intersección con el eje y (el valor de <span class="math">y</span> cuando <span class="math">x = 0</span>).</li>
        </ul>
        <p>En el aprendizaje automático, esta ecuación se escribe como:</p>
        <p class="math">y' = b + w₁x₁</p>
        <p>Donde:</p>
        <ul>
            <li><span class="math">y'</span>: es la predicción del modelo (etiqueta predicha).</li>
            <li><span class="math">b</span>: es el sesgo (<em>bias</em>), equivalente a la intersección con el eje y.</li>
            <li><span class="math">w₁</span>: es el peso (<em>weight</em>) de la característica, equivalente a la pendiente.</li>
            <li><span class="math">x₁</span>: es la característica de entrada.</li>
        </ul>
        <p>Figura 2: Representación matemática del modelo lineal.</p>
        <img src="placeholder_linear_equation.png" alt="Ecuación de regresión lineal">
        <p>En nuestro ejemplo, después de entrenar el modelo, se obtuvo un sesgo de 34 y un peso de -4.6, dando como resultado la ecuación <span class="math">y' = 34 - 4.6x₁</span>. Usando esta ecuación, un automóvil de 4,000 libras tendría una eficiencia predicha de 15.6 millas por galón.</p>
        <p>Figura 3: Gráfico con la línea de mejor ajuste y el punto predicho (4, 15.6).</p>
        <img src="placeholder_best_fit_line.png" alt="Línea de mejor ajuste">

        <h4>Modelos con Múltiples Características</h4>
        <p>En casos más complejos, la regresión lineal puede incluir múltiples características. Por ejemplo, para predecir la eficiencia de combustible, podríamos usar características adicionales como:</p>
        <ul>
            <li>Desplazamiento del motor</li>
            <li>Aceleración</li>
            <li>Número de cilindros</li>
            <li>Potencia (caballos de fuerza)</li>
        </ul>
        <p>La ecuación para un modelo con múltiples características es:</p>
        <p class="math">y' = b + w₁x₁ + w₂x₂ + ... + wₙxₙ</p>
        <p>Donde cada <span class="math">wᵢ</span> representa el peso de la característica <span class="math">xᵢ</span>.</p>

        <h3>Pérdida (<em>Loss</em>)</h3>
        <p>La pérdida es una métrica numérica que mide cuán erróneas son las predicciones de un modelo en comparación con los valores reales. El objetivo del entrenamiento es minimizar la pérdida. La pérdida se visualiza como la distancia entre los valores predichos y los valores reales.</p>
        <p>Figura 4: Líneas de pérdida que conectan los puntos de datos con el modelo, mostrando la distancia entre los valores reales y predichos.</p>
        <img src="placeholder_loss_lines.png" alt="Líneas de pérdida">

        <h4>Tipos de Pérdida</h4>
        <p>En la regresión lineal, se utilizan principalmente dos tipos de pérdida:</p>
        <table>
            <tr><th>Tipo de Pérdida</th><th>Definición</th><th>Ecuación</th></tr>
            <tr><td>Pérdida L1</td><td>Suma de los valores absolutos de la diferencia entre los valores predichos y reales.</td><td class="math">L1 = |y - y'|</td></tr>
            <tr><td>Error Absoluto Medio (MAE)</td><td>Promedio de las pérdidas L1 sobre un conjunto de N ejemplos.</td><td class="math">MAE = (1/N) * Σ|y - y'|</td></tr>
            <tr><td>Pérdida L2</td><td>Suma de las diferencias al cuadrado entre los valores predichos y reales.</td><td class="math">L2 = (y - y')²</td></tr>
            <tr><td>Error Cuadrático Medio (MSE)</td><td>Promedio de las pérdidas L2 sobre un conjunto de N ejemplos.</td><td class="math">MSE = (1/N) * Σ(y - y')²</td></tr>
        </table>
        <p>La diferencia principal entre L1 y L2 (o MAE y MSE) es que L2 penaliza más los errores grandes al elevarlos al cuadrado, mientras que L1 trata todos los errores de manera lineal.</p>
        <p>Ejemplo de cálculo de pérdida L2: Si el modelo predice 23.1 millas por galón para un automóvil de 2,370 libras, pero el valor real es 26 millas por galón, la pérdida L2 se calcula como:</p>
        <p class="math">L2 = (26 - 23.1)² = 8.41</p>

        <h4>Elección de la Pérdida</h4>
        <p>La elección entre MAE y MSE depende del conjunto de datos y de cómo se deseen manejar los valores atípicos (<em>outliers</em>). MSE penaliza más los errores grandes, lo que hace que el modelo se ajuste más a los valores atípicos. MAE, por otro lado, es menos sensible a los valores atípicos, lo que resulta en un modelo que se ajusta mejor a la mayoría de los datos.</p>
        <p>Figura 5: Modelo entrenado con MSE, más cercano a los valores atípicos.</p>
        <img src="placeholder_mse_model.png" alt="Modelo entrenado con MSE">
        <p>Figura 6: Modelo entrenado con MAE, más alejado de los valores atípicos.</p>
        <img src="placeholder_mae_model.png" alt="Modelo entrenado con MAE">

        <h3>Descenso por Gradiente</h3>
        <p>El descenso por gradiente es una técnica matemática que ajusta iterativamente los pesos y el sesgo del modelo para minimizar la pérdida. El proceso consiste en:</p>
        <ol>
            <li>Iniciar con pesos y sesgo aleatorios cercanos a cero.</li>
            <li>Calcular la pérdida con los pesos y sesgo actuales.</li>
            <li>Determinar la dirección que reduce la pérdida (usando el gradiente).</li>
            <li>Actualizar los pesos y el sesgo en pequeños incrementos en esa dirección.</li>
            <li>Repetir hasta que la pérdida no pueda reducirse más (convergencia).</li>
        </ol>
        <p>Figura 7: Ilustración del proceso de descenso por gradiente.</p>
        <img src="placeholder_gradient_descent.png" alt="Descenso por gradiente">

        <h4>Curvas de Pérdida y Convergencia</h4>
        <p>Una curva de pérdida muestra cómo cambia la pérdida a medida que el modelo entrena. Una curva típica muestra una disminución rápida al inicio, seguida de una estabilización cuando el modelo converge.</p>
        <p>Figura 8: Curva de pérdida que muestra convergencia alrededor de la iteración 1,000.</p>
        <img src="placeholder_loss_curve.png" alt="Curva de pérdida">
        <p>Figura 9: Instantáneas del modelo en diferentes etapas del entrenamiento, mostrando cómo mejora con el tiempo.</p>
        <img src="placeholder_training_snapshots.png" alt="Instantáneas del entrenamiento">

        <h4>Superficie de Pérdida Convexa</h4>
        <p>En la regresión lineal, la superficie de pérdida es siempre convexa, lo que garantiza que el descenso por gradiente encuentre el mínimo global. La figura siguiente muestra una superficie de pérdida para un modelo con una característica:</p>
        <p>Figura 10: Superficie de pérdida convexa con el mínimo en (peso = -5.44, sesgo = 35.94, pérdida = 5.54).</p>
        <img src="placeholder_loss_surface.png" alt="Superficie de pérdida">

        <h3>Hiperparámetros</h3>
        <p>Los hiperparámetros son variables que controlan el proceso de entrenamiento, a diferencia de los parámetros (pesos y sesgo) que el modelo calcula. Los principales hiperparámetros son:</p>

        <h4>Tasa de Aprendizaje (<em>Learning Rate</em>)</h4>
        <p>La tasa de aprendizaje determina el tamaño de los ajustes a los pesos y el sesgo en cada iteración. Una tasa demasiado baja hace que el modelo converja lentamente, mientras que una tasa demasiado alta puede hacer que el modelo no converja. La figura siguiente muestra el impacto de diferentes tasas de aprendizaje:</p>
        <p>Figura 11: Curva de pérdida con una tasa de aprendizaje ideal.</p>
        <img src="placeholder_ideal_lr.png" alt="Tasa de aprendizaje ideal">
        <p>Figura 12: Curva de pérdida con una tasa de aprendizaje demasiado baja.</p>
        <img src="placeholder_low_lr.png" alt="Tasa de aprendizaje baja">
        <p>Figura 13: Curva de pérdida con una tasa de aprendizaje demasiado alta.</p>
        <img src="placeholder_high_lr.png" alt="Tasa de aprendizaje alta">

        <h4>Tamaño del Lote (<em>Batch Size</em>)</h4>
        <p>El tamaño del lote determina cuántos ejemplos procesa el modelo antes de actualizar los pesos y el sesgo. Las opciones incluyen:</p>
        <ul>
            <li><strong>Descenso por gradiente estocástico (SGD):</strong> Usa un solo ejemplo por iteración, lo que introduce ruido en la curva de pérdida.</li>
            <li><strong>Descenso por gradiente de mini-lotes:</strong> Usa un subconjunto de ejemplos, equilibrando ruido y eficiencia.</li>
        </ul>
        <p>Figura 14: Curva de pérdida con SGD, mostrando ruido.</p>
        <img src="placeholder_sgd_loss.png" alt="Curva de pérdida SGD">
        <p>Figura 15: Curva de pérdida con mini-lotes, con menos ruido.</p>
        <img src="placeholder_minibatch_loss.png" alt="Curva de pérdida mini-lotes">

        <h4>Épocas (<em>Epochs</em>)</h4>
        <p>Una época ocurre cuando el modelo ha procesado todos los ejemplos del conjunto de datos una vez. El número de épocas es un hiperparámetro que afecta el tiempo de entrenamiento y la calidad del modelo.</p>
        <p>Figura 16: Comparación entre lote completo, mini-lotes y épocas.</p>
        <img src="placeholder_batch_epoch.png" alt="Lote vs. Épocas">
    </section>

    <section id="problema">
        <h2>1. Problem Statement</h2>
        <p>Este proyecto analiza los derrames de agua producida reportados por la industria del petróleo y gas en Texas entre 2013 y 2022. Los datos provienen de informes oficiales de la Comisión de Ferrocarriles de Texas (RRC), detallando más de 10,000 incidentes durante este período. El conjunto de datos incluye variables como la fecha del derrame, el nombre del operador, el condado de ocurrencia, el tipo de operación, la fuente y la causa probable del derrame, y los volúmenes derramados y recuperados.</p>
        <p>El agua producida contiene sustancias tóxicas como metales pesados, residuos de hidrocarburos y químicos utilizados en la fracturación hidráulica, lo que representa una amenaza significativa para el medio ambiente y la salud pública. Este análisis busca entender la magnitud, recurrencia y distribución espacial de tales incidentes para identificar zonas críticas, evaluar la responsabilidad del operador y proponer estrategias de gestión ambiental más efectivas.</p>
    </section>

    <section id="introduccion">
        <h2>2. Introducción</h2>
        <p>El agua producida representa riesgos ambientales y de salud significativos cuando no se gestiona adecuadamente. En Texas, se reportaron más de 10,000 derrames totalizando más de 148 millones de galones entre 2013 y 2022; solo alrededor del 40% de ese volumen fue recuperado, dejando el resto para impactar el suelo, el agua y los ecosistemas. El agua producida puede contener toxinas como benceno, metales pesados, radio y salinidad elevada, que se han relacionado con la degradación del suelo, la pérdida de vegetación, la mortalidad de la vida silvestre y la contaminación de acuíferos.</p>
        <p>Figura 17: Visualización geográfica de derrames de agua producida en Texas usando QGIS.</p>
        <img src="placeholder_qgis_map.png" alt="Visualización geográfica de derrames">
    </section>

    <section id="objetivos">
        <h2>3. Objetivos</h2>
        <h3>3.1 Objetivo General</h3>
        <p>Desarrollar un modelo multitarea basado en Keras que prediga simultáneamente el volumen de agua producida derramada y su causa probable, utilizando Optuna para la optimización de hiperparámetros.</p>
        <h3>3.2 Objetivos Específicos</h3>
        <ul>
            <li>Preprocesar el conjunto de datos utilizando transformaciones logarítmicas, codificación one-hot y división de fechas.</li>
            <li>Diseñar una arquitectura neuronal con capas ocultas compartidas y cabezales separados para regresión y clasificación.</li>
            <li>Optimizar los hiperparámetros del modelo mediante Optuna en variables arquitectónicas y de entrenamiento.</li>
            <li>Evaluar utilizando R², MAE, MSE y Accuracy.</li>
            <li>Automatizar la identificación y reutilización de la mejor configuración para el despliegue.</li>
        </ul>
    </section>

    <section id="resumen">
        <h2>4. Resumen y Métricas Clave</h2>
        <p>Esta aplicación presenta un modelo de red neuronal diseñado para una doble tarea: predecir el volumen de agua derramada (regresión) y su causa probable (clasificación). Mediante la optimización automática con Optuna, el modelo logra un rendimiento prometedor, demostrando el potencial de los enfoques multitarea en contextos industriales complejos. A continuación se presentan los resultados finales más importantes.</p>
        <ul>
            <li><strong>Coeficiente R² (Volumen):</strong> 0.347</li>
            <li><strong>Precisión (Causa):</strong> 49.8%</li>
            <li><strong>Error Absoluto Medio:</strong> 1.279</li>
            <li><strong>Error Cuadrático Medio:</strong> 2.764</li>
        </ul>
    </section>

    <section id="metodologia">
        <h2>5. Metodología Interactiva</h2>
        <p>El modelo fue construido siguiendo un flujo de trabajo automatizado que va desde el preprocesamiento de los datos hasta la optimización de la arquitectura de la red neuronal. Este enfoque asegura la reproducibilidad y facilita la mejora continua del sistema.</p>
        <h3>5.1 Preparación de Datos</h3>
        <ul>
            <li><strong>Valores faltantes:</strong> imputados utilizando la mediana y marcadores de posición 'Desconocido'.</li>
            <li><strong>Transformación logarítmica:</strong> aplicada a los volúmenes de derrame para manejar la asimetría.</li>
            <li><strong>Codificación:</strong> variables categóricas codificadas one-hot; fechas divididas en año/mes.</li>
            <li><strong>Escalado:</strong> características normalizadas utilizando MinMaxScaler.</li>
        </ul>
        <p><strong>📊 1. Preprocesamiento de Datos</strong></p>
        <p>Se utilizó un conjunto de datos real de derrames. Las variables categóricas (operador, condado, causa, etc.) fueron transformadas con OneHotEncoder, mientras que a la variable objetivo de volumen se le aplicó una transformación logarítmica para estabilizar la varianza.</p>
        <p><strong>🧠 2. Modelo de Red Neuronal Multitarea</strong></p>
        <p>El núcleo del sistema es una red neuronal con capas compartidas que aprenden características comunes de los datos. El modelo se bifurca en dos salidas especializadas:</p>
        <ul>
            <li><strong>Salida de Regresión:</strong> Una capa densa con activación lineal para predecir el volumen del derrame.</li>
            <li><strong>Salida de Clasificación:</strong> Una capa densa con activación Softmax para predecir la probabilidad de cada causa posible.</li>
        </ul>
        <p><strong>⚙️ 3. Optimización con Optuna</strong></p>
        <p>Para encontrar la mejor configuración, se usó Optuna, un framework de optimización bayesiana que ajustó automáticamente los siguientes hiperparámetros clave para minimizar la pérdida combinada del modelo:</p>
        <ul>
            <li>Capas</li>
            <li>Neuronas</li>
            <li>Dropout</li>
            <li>Regularización L2</li>
            <li>Tasa de Aprendizaje</li>
            <li>Optimizador</li>
            <li>Tamaño de Lote</li>
        </ul>
    </section>

    <section id="experimentacion">
        <h2>6. Experimentación y Resultados</h2>
        <h3>6.1 Plataforma Computacional</h3>
        <p>El desarrollo del modelo siguió un flujo de trabajo computacional estructurado. El prototipado inicial se realizó en el IDE Spyder, donde se diseñaron y probaron versiones tempranas de la red neuronal utilizando muestras pequeñas de datos y arquitecturas simplificadas. Una vez definida la arquitectura central, el proyecto migró a Google Colab para aprovechar su aceleración gratuita de GPU.</p>
        <h3>6.2 Análisis de Rendimiento del Modelo</h3>
        <p>Esta sección detalla el rendimiento de la red neuronal multitarea en varias métricas para la predicción del volumen de derrame (regresión) y la causa del derrame (clasificación).</p>
        <h4>Pérdida Total</h4>
        <table>
            <tr><th>Época</th><th>Pérdida de Entrenamiento</th><th>Pérdida de Validación</th><th>Diferencia</th></tr>
            <tr><td>1</td><td>62.2842</td><td>45.1358</td><td>17.1484</td></tr>
            <tr><td>6</td><td>7.2674</td><td>4.8145</td><td>2.4529</td></tr>
            <tr><td>11</td><td>5.6395</td><td>4.6213</td><td>1.0182</td></tr>
            <tr><td>16</td><td>4.9681</td><td>4.6037</td><td>0.3645</td></tr>
            <tr><td>21</td><td>4.5250</td><td>4.6631</td><td>0.1382</td></tr>
            <tr><td>26</td><td>4.3510</td><td>4.6861</td><td>0.3352</td></tr>
            <tr><td>27</td><td>4.2380</td><td>4.7025</td><td>0.4644</td></tr>
        </table>
        <p>Figura 18: Pérdida total de entrenamiento y validación por época.</p>
        <img src="placeholder_loss_plot.png" alt="Pérdida total por época">
        <h4>Precisión de Clasificación</h4>
        <table>
            <tr><th>Época</th><th>Precisión de Entrenamiento</th><th>Precisión de Validación</th><th>Diferencia</th></tr>
            <tr><td>1</td><td>0.0726</td><td>0.0145</td><td>0.0581</td></tr>
            <tr><td>6</td><td>0.4658</td><td>0.4939</td><td>0.0281</td></tr>
            <tr><td>11</td><td>0.4837</td><td>0.4982</td><td>0.0145</td></tr>
            <tr><td>16</td><td>0.4930</td><td>0.5012</td><td>0.0082</td></tr>
            <tr><td>21</td><td>0.4988</td><td>0.4952</td><td>0.0036</td></tr>
            <tr><td>26</td><td>0.4989</td><td>0.5024</td><td>0.0035</td></tr>
            <tr><td>27</td><td>0.5032</td><td>0.5036</td><td>0.0005</td></tr>
        </table>
        <p>Figura 19: Precisión de clasificación de entrenamiento y validación por época.</p>
        <img src="placeholder_accuracy_plot.png" alt="Precisión por época">
        <h4>MAE de Regresión (Error Absoluto Medio)</h4>
        <table>
            <tr><th>Época</th><th>MAE de Entrenamiento</th><th>MAE de Validación</th><th>Diferencia</th></tr>
            <tr><td>1</td><td>7.1658</td><td>6.0034</td><td>1.1624</td></tr>
            <tr><td>6</td><td>1.8600</td><td>1.3799</td><td>0.4801</td></tr>
            <tr><td>11</td><td>1.5793</td><td>1.3305</td><td>0.2488</td></tr>
            <tr><td>16</td><td>1.4395</td><td>1.3250</td><td>0.1146</td></tr>
            <tr><td>21</td><td>1.3427</td><td>1.3326</td><td>0.0102</td></tr>
            <tr><td>26</td><td>1.3003</td><td>1.3313</td><td>0.0310</td></tr>
            <tr><td>27</td><td>1.2843</td><td>1.3365</td><td>0.0522</td></tr>
        </table>
        <p>Figura 20: MAE de regresión de entrenamiento y validación por época.</p>
        <img src="placeholder_mae_plot.png" alt="MAE por época">
        <h4>MSE de Regresión (Error Cuadrático Medio)</h4>
        <table>
            <tr><th>Época</th><th>MSE de Entrenamiento</th><th>MSE de Validación</th><th>Diferencia</th></tr>
            <tr><td>1</td><td>106.2713</td><td>89.1004</td><td>17.1709</td></tr>
            <tr><td>6</td><td>7.8123</td><td>5.7045</td><td>2.1078</td></tr>
            <tr><td>11</td><td>6.4232</td><td>5.2283</td><td>1.1949</td></tr>
            <tr><td>16</td><td>5.5246</td><td>5.1487</td><td>0.3759</td></tr>
            <tr><td>21</td><td>5.1062</td><td>5.1610</td><td>0.0548</td></tr>
            <tr><td>26</td><td>4.9517</td><td>5.1889</td><td>0.2372</td></tr>
            <tr><td>27</td><td>4.8493</td><td>5.2098</td><td>0.3605</td></tr>
        </table>
    </section>

    <section id="resultados">
        <h2>Resultados Clave</h2>
        <p>Visualización de regresión y clasificación sobre datos reales.</p>
        <h3>Predicción de Volumen</h3>
        <p>El modelo predice el volumen de agua derramada con un R² de 0.347 y un MAE de 1.279, indicando una capacidad moderada para capturar la variabilidad en los volúmenes de derrame.</p>
        <h3>Predicción de Causa</h3>
        <p>La precisión de clasificación alcanzó el 49.8%, con las causas más comunes identificadas como fallos mecánicos y corrosión.</p>
    </section>

    <section id="rendimiento">
        <h2>Explorador de Rendimiento</h2>
        <p>Explora cómo evolucionaron las métricas a lo largo de las épocas de entrenamiento.</p>
        <ul>
            <li><strong>Pérdida Total:</strong> La pérdida total disminuyó significativamente en las primeras épocas, estabilizándose alrededor de 4.2-4.7.</li>
            <li><strong>Precisión:</strong> La precisión de clasificación mejoró hasta alcanzar un máximo de 0.5297 en la época 31.</li>
            <li><strong>MAE:</strong> El MAE de regresión se redujo a 1.2843 en entrenamiento y 1.3365 en validación en la época 27.</li>
        </ul>
        <h3>Análisis de Datos</h3>
        <p>El análisis de datos reveló patrones significativos:</p>
        <ul>
            <li><strong>Causas principales de derrames:</strong></li>
            <table>
                <tr><th>Causa</th><th>Conteo</th><th>Volumen de Petróleo Derramado (barriles)</th><th>Volumen de Agua Producida Derramada (barriles)</th></tr>
                <tr><td>CORROSION</td><td>259</td><td>-</td><td>-</td></tr>
                <tr><td>MECHANICAL FAILURE</td><td>183</td><td>-</td><td>-</td></tr>
                <tr><td>WEATHER</td><td>47</td><td>-</td><td>-</td></tr>
                <tr><td>HUMAN ERROR</td><td>39</td><td>-</td><td>-</td></tr>
                <tr><td>THEFT / VANDALISM</td><td>1</td><td>-</td><td>-</td></tr>
            </table>
            <li><strong>Análisis por operador (ejemplo: APACHE):</strong></li>
            <table>
                <tr><th>Métrica</th><th>Valor</th></tr>
                <tr><td>Total derrames</td><td>287</td></tr>
                <tr><td>Petróleo total derramado</td><td>437312.40 barriles</td></tr>
                <tr><td>Agua producida total derramada</td><td>6307518.00 barriles</td></tr>
            </table>
            <li><strong>Análisis por condado (ejemplo: Andrews):</strong></li>
            <table>
                <tr><th>Métrica</th><th>Valor</th></tr>
                <tr><td>Total derrames</td><td>529</td></tr>
                <tr><td>Petróleo total derramado</td><td>365615.21 barriles</td></tr>
                <tr><td>Agua producida total derramada</td><td>6746821.12 barriles</td></tr>
            </table>
        </ul>
        <h3>Visualizaciones</h3>
        <p>Se generaron varias visualizaciones para explorar los datos:</p>
        <ul>
            <li><strong>Derrames por mes:</strong> Gráfico de líneas mostrando la tendencia mensual de derrames.</li>
            <li><strong>Relación petróleo vs agua:</strong> Gráfico de dispersión logarítmico.</li>
            <li><strong>Derrames en agua vs tierra:</strong> Gráfico de barras.</li>
            <li><strong>Gráfico 3D:</strong> Visualización de derrames por año, mes y volumen logarítmico.</li>
        </ul>
    </section>

    <section id="discusion">
        <h2>7. Discusión</h2>
        <p>A pesar de las limitaciones en la precisión de las predicciones, los resultados muestran una clara tendencia hacia la mejora del modelo con el aumento de datos y la optimización. El desempeño de la regresión (R² ≈ 0.35) y clasificación (≈ 50%) sugiere que el enfoque multitarea puede capturar patrones útiles incluso en conjuntos de datos con ruido e incertidumbre.</p>
        <p>Se identificaron operadores y condados con altas tasas de derrames, lo que puede guiar intervenciones regulatorias. Además, la causa más común de los derrames fue el fallo de equipos, destacando la necesidad de mantenimiento preventivo en infraestructura.</p>
    </section>

    <section id="predicciones">
        <h2>Predicciones</h2>
        <p>El modelo predice tanto el volumen de agua derramada como la causa probable. Ejemplo de predicciones:</p>
        <table>
            <tr><th>PREDICTED_LOG_WATER</th><th>OBSERVED_LOG_WATER</th><th>L1_LOSS_WATER</th><th>PREDICTED_CAUSE</th></tr>
            <tr><td>9.30</td><td>8.34</td><td>0.96</td><td>CORROSION</td></tr>
            <tr><td>8.25</td><td>6.73</td><td>1.52</td><td>MECHANICAL FAILURE</td></tr>
            <tr><td>7.31</td><td>4.44</td><td>2.86</td><td>MECHANICAL FAILURE</td></tr>
            <tr><td>8.54</td><td>6.66</td><td>0.16</td><td>MECHANICAL FAILURE</td></tr>
            <tr><td>7.49</td><td>9.04</td><td>1.56</td><td>MECHANICAL FAILURE</td></tr>
        </table>
    </section>

    <section id="aplicacion">
        <h2>8. Aplicación Web</h2>
        <p>Se desarrolló una aplicación web interactiva que permite cargar datos y predecir en tiempo real tanto el volumen estimado de agua derramada como su causa probable. Esta herramienta puede ser utilizada por reguladores, investigadores y operadores para monitorear riesgos y responder de forma proactiva.</p>
        <h3>Interfaz de Predicciones</h3>
        <p>La aplicación incluye dropdowns para seleccionar valores de entrada (año, mes, operador, condado, tipo de operación, fuente) y un botón para ejecutar predicciones. Ejemplo de uso:</p>
        <pre>
# Ejemplo de código para la interfaz de predicciones
import pandas as pd
import numpy as np
import tensorflow as tf
import joblib
import os
from IPython.display import display
import ipywidgets as widgets
from tensorflow.keras.models import load_model
from tensorflow.keras.metrics import MeanSquaredError

def format_currency(x):
    return "{:.2f}".format(x)

def predict_outcomes(model, df, features, le_causa, preprocessor, batch_size=1):
    batch = df.copy()
    batch.set_index(np.arange(len(batch)), inplace=True)
    X_batch = preprocessor.transform(batch[features])
    predictions = model.predict(X_batch, verbose=0)
    y_reg_pred = predictions[0].flatten()
    y_clf_pred = np.argmax(predictions[1], axis=1)
    data = {
        "PREDICTED_WATER": [format_currency(np.expm1(y)) for y in y_reg_pred],
        "PREDICTED_CAUSE": [le_causa.inverse_transform([y])[0] for y in y_clf_pred]
    }
    return pd.DataFrame(data)

def show_predictions(output):
    header = "\n" + "="*50 + "\n" + "| " + "PREDICCIONES".center(48) + " |\n" + "="*50
    print(header)
    for _, row in output.iterrows():
        print(f"Cantidad Derramada: {row['PREDICTED_WATER']} barriles")
        print(f"Causa Probable: {row['PREDICTED_CAUSE']}")

def load_required_files():
    try:
        required_files = ["spill_data_cleaned.csv", "modelo_trained.h5", "preprocessor.pkl", "labelencoder_causa.pkl"]
        missing_files = [f for f in required_files if not os.path.exists(f)]
        if missing_files:
            print(f"Archivos faltantes: {missing_files}")
            return None, None, None, None
        model = load_model("modelo_trained.h5", custom_objects={"mse": MeanSquaredError()})
        preprocessor = joblib.load("preprocessor.pkl")
        le_causa = joblib.load("labelencoder_causa.pkl")
        df = pd.read_csv("spill_data_cleaned.csv", sep=",", encoding="latin-1")
        return model, preprocessor, le_causa, df
    except Exception as e:
        print(f"Error cargando archivos: {e}")
        return None, None, None, None

def get_unique_values(df, column):
    unique_values = df[column].astype(str).str.strip().unique()
    return sorted([x for x in unique_values if str(x).lower() != 'nan'])

def create_dropdowns(df, model, preprocessor, le_causa):
    features = ['year', 'month', 'operator_edit', 'county_edit', 'type_operation', 'source']
    year_dropdown = widgets.Dropdown(options=get_unique_values(df, 'year'), description='Año:')
    month_dropdown = widgets.Dropdown(options=get_unique_values(df, 'month'), description='Mes:')
    operator_dropdown = widgets.Dropdown(options=get_unique_values(df, 'operator_edit'), description='Operador:')
    county_dropdown = widgets.Dropdown(options=get_unique_values(df, 'county_edit'), description='Condado:')
    type_operation_dropdown = widgets.Dropdown(options=get_unique_values(df, 'type_operation'), description='Operación:')
    source_dropdown = widgets.Dropdown(options=get_unique_values(df, 'source'), description='Fuente:')
    predict_button = widgets.Button(description="Hacer Predicción", button_style='success', tooltip='Click para hacer predicción')
    output = widgets.Output()

    def on_predict_button_clicked(b):
        with output:
            output.clear_output()
            if model is None or preprocessor is None or le_causa is None:
                print("Error: Modelo, preprocesador o codificador de etiquetas no cargados")
                return
            input_data = {
                'year': [year_dropdown.value],
                'month': [month_dropdown.value],
                'operator_edit': [operator_dropdown.value],
                'county_edit': [county_dropdown.value],
                'type_operation': [type_operation_dropdown.value],
                'source': [source_dropdown.value]
            }
            input_df = pd.DataFrame(input_data)
            try:
                pred_df = predict_outcomes(model, input_df, features, le_causa, preprocessor, batch_size=1)
                show_predictions(pred_df)
            except Exception as e:
                print(f"Error al hacer predicción: {e}")

    predict_button.on_click(on_predict_button_clicked)
    display(widgets.VBox([year_dropdown, month_dropdown, operator_dropdown, county_dropdown, type_operation_dropdown, source_dropdown, predict_button, output]))

def main():
    print("Iniciando script de predicción con dropdowns...")
    model, preprocessor, le_causa, df = load_required_files()
    if model is None or preprocessor is None or le_causa is None or df is None:
        print("No se pudieron cargar los archivos necesarios. Terminando ejecución.")
        return
    print("Archivos cargados correctamente. Selecciona los valores para la predicción.")
    create_dropdowns(df, model, preprocessor, le_causa)

if __name__ == "__main__":
    main()
        </pre>
    </section>

    <section id="conclusiones">
        <h2>9. Conclusiones</h2>
        <p>Este proyecto demuestra el potencial de la inteligencia artificial para abordar problemas ambientales complejos. El modelo multitarea logró resultados competitivos en la predicción de variables clave, y su integración con una interfaz web proporciona un sistema práctico para usuarios no técnicos.</p>
        <p>Como futuras mejoras, se plantea incrementar el volumen de datos, refinar el tratamiento de valores atípicos y explorar arquitecturas más sofisticadas como redes recurrentes o transformers para aprovechar patrones temporales más complejos.</p>
    </section>

    <section id="codigo">
        <h2>10. Código y Detalles Técnicos</h2>
        <h3>10.1 Instalación de Optuna</h3>
        <pre>
pip install optuna
# Salida: Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)
# Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.4)
# Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna)...
        </pre>
        <p>El comando ejecuta la instalación de la librería Optuna, una herramienta de optimización de hiperparámetros para modelos de aprendizaje automático. Se utiliza desde la línea de comandos en un entorno con Python y pip instalados.</p>

        <h3>10.2 Configuración del Entorno</h3>
        <pre>
import pandas as pd
import numpy as np
import json
import os
import optuna
import matplotlib.pyplot as plt
import tensorflow as tf
import warnings
import base64
import requests
import re
import joblib
from datetime import datetime
from sklearn.model_selection import train_test_split
from tensorflow.keras.optimizers import Adam, RMSprop, SGD
from tensorflow.keras.regularizers import l2
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
        </pre>
        <p>Este código importa las librerías necesarias para el modelado, incluyendo pandas para manipulación de datos, numpy para cálculos numéricos, tensorflow para redes neuronales, y optuna para optimización de hiperparámetros.</p>

        <h3>10.3 Preprocesamiento de Datos</h3>
        <pre>
df = pd.read_csv("spill_data_cleaned.csv", sep=';', encoding='latin-1')
df = df.dropna(subset=['release_prod_water_edit'])
df['log_release_prod_water_edit'] = np.log10(df['release_prod_water_edit'])
cat_cols = ['operator_edit', 'county_edit', 'type_operation', 'source', 'probable_cause_edit']
for col in cat_cols:
    df[col] = df[col].fillna('unknown').astype(str).str.lower()
df['date'] = pd.to_datetime(df['date_of_spill_edit'])
df['month'] = df['date'].dt.month
df['year'] = df['date'].dt.year
df.drop(columns=['date'], inplace=True)
y_reg = df['log_release_prod_water_edit']
y_clf = df['probable_cause_edit']
X = df[['year', 'month', 'operator_edit', 'county_edit', 'type_operation', 'source']]
num_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
cat_features = X.select_dtypes(include=['object']).columns.tolist()
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), num_features),
    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)
])
X_processed = preprocessor.fit_transform(X)
        </pre>
        <p>Este código carga el conjunto de datos, elimina valores nulos, aplica transformación logarítmica a los volúmenes de agua derramada, codifica variables categóricas y normaliza las características numéricas.</p>

        <h3>10.4 Generación de Gráficos</h3>
        <pre>
def make_plots(df, feature_names, label_name, model_output, sample_size=200):
    random_sample = df.sample(n=sample_size).copy()
    random_sample.reset_index(drop=True, inplace=True)
    weights, bias, epochs, metrics = model_output
    is_2d_plot = len(feature_names) == 1
    # Código para generar gráficos 2D/3D con Plotly
def plot_data(df, features, label, fig):
    if len(features) == 1:
        scatter = px.scatter(df, x=features[0], y=label, color=df['probable_cause_edit'])
    else:
        scatter = px.scatter_3d(df, x=features[0], y=features[1], z=label, color=df['probable_cause_edit'])
    fig.add_trace(scatter.data[0], row=1, col=2)
    if len(features) == 1:
        fig.update_xaxes(title_text=features[0], row=1, col=2)
        fig.update_yaxes(title_text=label, row=1, col=2)
    else:
        fig.update_layout(scene=dict(
            xaxis_title=features[0],
            yaxis_title=features[1],
            zaxis_title=label
        ))
def plot_model(df, features, weights, bias, fig):
    df['REG_PREDICTED'] = bias[0]
    for index, feature in enumerate(features):
        df['REG_PREDICTED'] += df[feature] * weights[index][0]
    # Código para graficar predicciones
def plot_loss_curve(epochs, metric, fig):
    fig.add_trace(go.Scatter(x=epochs, y=metric, mode='lines', name='Loss'))
    fig.update_yaxes(title_text="Classification Accuracy", row=1, col=1, range=[metric.min()*0.8, metric.max()])
        </pre>
        <p>Estas funciones generan visualizaciones 2D y 3D de los datos y las predicciones del modelo utilizando Plotly.</p>

        <h3>10.5 Optimización con Optuna</h3>
        <pre>
def objective(trial):
    n_layers = trial.suggest_int("n_layers", 2, 4)
    dropout_rate = trial.suggest_float("dropout_rate", 0.1, 0.5)
    l2_reg = trial.suggest_float("l2_reg", 1e-6, 1e-2, log=True)
    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)
    optimizer_name = trial.suggest_categorical('optimizer', ['adam', 'rmsprop'])
    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])
    use_batch_norm = trial.suggest_categorical('use_batch_norm', [True, False])
    input_layer = Input(shape=(input_dim,))
    x = input_layer
    for i in range(n_layers):
        x = Dense(trial.suggest_int(f'units_{i}', 16, 128))(x)
        if use_batch_norm:
            x = BatchNormalization()(x)
        x = Dropout(dropout_rate)(x)
    regression_output = Dense(1, name='regression')(x)
    classification_output = Dense(num_classes, activation='softmax', name='classification')(x)
    model = Model(inputs=input_layer, outputs=[regression_output, classification_output])
    if optimizer_name == 'adam':
        optimizer = Adam(learning_rate=learning_rate)
    else:
        optimizer = RMSprop(learning_rate=learning_rate)
    model.compile(
        optimizer=optimizer,
        loss={'regression': 'mae', 'classification': 'categorical_crossentropy'},
        loss_weights={'regression': 0.5, 'classification': 0.5},
        metrics={'regression': ['mae'], 'classification': ['accuracy']}
    )
    history = model.fit(
        X_train_opt,
        {'regression': y_reg_train_opt, 'classification': y_clf_train_opt},
        validation_data=(X_val_opt, {'regression': y_reg_val_opt, 'classification': y_clf_val_opt}),
        epochs=30,
        batch_size=batch_size,
        verbose=0
    )
    return history.history['val_loss'][-1]
        </pre>
        <p>Esta función define el objetivo de optimización para Optuna, ajustando hiperparámetros como el número de capas, tasa de dropout, regularización L2, y optimizador.</p>

        <h3>10.6 Guardado y Carga de Parámetros</h3>
        <pre>
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
best_params_data = {
    'timestamp': timestamp,
    'best_value': study.best_value,
    'best_params': study.best_params,
    'n_trials': len(study.trials),
    'optimization_complete': True
}
filename = f'best_params_{timestamp}.json'
with open(filename, 'w') as f:
    json.dump(best_params_data, f, indent=2)
print(f"Optimización completada! Mejores parámetros guardados en: {filename}")

def load_best_params_from_json(json_filename):
    if not os.path.exists(json_filename):
        raise FileNotFoundError(f"El archivo {json_filename} no existe")
    with open(json_filename, 'r') as f:
        data = json.load(f)
    print(f"Archivo: {json_filename}, Timestamp: {data['timestamp']}, Mejor pérdida: {data['best_value']:.4f}")
    return data['best_params']

def load_and_compare_all_params(json_files):
    if not json_files:
        print("No se encontraron archivos de parámetros")
        return None, None
    best_score = -float('inf')
    best_params = None
    best_file = None
    for filename in json_files:
        try:
            with open(filename, 'r') as f:
                data = json.load(f)
            if 'metrics' in data and isinstance(data['metrics'], dict):
                r2 = data['metrics'].get('r2', 0)
                accuracy = data['metrics'].get('accuracy', 0)
                if isinstance(r2, (int, float)) and isinstance(accuracy, (int, float)):
                    score = r2 * 0.6 + accuracy * 0.4
                    score_source = f'metrics (R2: {r2:.3f}, Acc: {accuracy:.3f})'
            elif 'best_value' in data and isinstance(data['best_value'], (int, float)):
                score = -data['best_value']
                score_source = f"Optuna best_value ({data['best_value']})"
            else:
                score = os.path.getmtime(filename)
                score_source = "timestamp (fallback)"
            print(f"{filename}: score {score:.4f} ({score_source})")
            if score > best_score:
                best_score = score
                best_params = data.get('best_params', data)
                best_file = filename
        except Exception as e:
            print(f"Error cargando {filename}: {e}")
    if best_file:
        print(f"Mejor archivo seleccionado: {best_file} (score: {best_score:.4f})")
        return best_file, best_params
    return None, None
        </pre>
        <p>Estas funciones guardan y comparan los mejores parámetros encontrados por Optuna, seleccionando el mejor modelo basado en métricas o fecha de modificación.</p>

        <h3>10.7 Modelo Final y Evaluación</h3>
        <pre>
def build_model_from_params(best_params, input_dim, num_classes):
    n_layers = best_params.get('n_layers', 2)
    dropout_rate = best_params.get('dropout_rate', 0.2)
    l2_reg = best_params.get('l2_reg', 1e-4)
    learning_rate = best_params.get('learning_rate', 1e-3)
    optimizer_name = best_params.get('optimizer', 'adam')
    input_layer = Input(shape=(input_dim,))
    x = input_layer
    for i in range(n_layers):
        x = Dense(best_params.get(f'units_{i}', 64), kernel_regularizer=l2(l2_reg))(x)
        x = Dropout(dropout_rate)(x)
    regression_output = Dense(1, name='regression')(x)
    classification_output = Dense(num_classes, activation='softmax', name='classification')(x)
    model = Model(inputs=input_layer, outputs=[regression_output, classification_output])
    if optimizer_name == 'adam':
        optimizer = Adam(learning_rate=learning_rate)
    else:
        optimizer = RMSprop(learning_rate=learning_rate)
    model.compile(
        optimizer=optimizer,
        loss={'regression': 'mse', 'classification': 'categorical_crossentropy'},
        metrics={'regression': ['mae'], 'classification': ['accuracy']}
    )
    return model

model.save("modelo_trained.h5")
joblib.dump(preprocessor, "preprocessor.pkl")
print("Modelo guardado en modelo_trained.h5")
print("Preprocesor guardado en preprocessor.pkl")

test_results = model.evaluate(X_test, {'regression': y_reg_test, 'classification': y_clf_test}, verbose=0)
print(f"Resultados en test: R2: {r2:.4f}, MSE: {mse:.4f}, MAE: {mae:.4f}, Accuracy: {accuracy:.4f}")
        </pre>
        <p>Este código construye el modelo final con los mejores parámetros, lo guarda en disco y evalúa su rendimiento en el conjunto de prueba.</p>

        <h3>10.8 Visualización Adicional</h3>
        <pre>
plt.figure(figsize=(15, 10))
plt.subplot(2, 2, 1)
monthly_spills = df.groupby('month').size()
monthly_spills.plot(kind='bar')
plt.title('Derrames por mes')
plt.subplot(2, 2, 2)
plt.scatter(np.log10(df['release_crude_oil_edit']), np.log10(df['release_prod_water_edit']), alpha=0.6)
plt.title('Relación entre petróleo y agua producida derramada')
plt.xlabel('Petróleo derramado (barriles) - escala log')
plt.ylabel('Agua producida derramada (barriles) - escala log')
plt.subplot(2, 2, 4)
water_spills = df['spill_on_water_edit'].value_counts()
water_spills.plot(kind='bar', color=['salmon', 'lightgreen'])
plt.title('Derrames en agua vs tierra')
plt.xticks([0, 1], ['Tierra', 'Agua'], rotation=0)
plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 6))
monthly_trend = df.resample('M', on='date_of_spill_edit').agg({
    'release_crude_oil_edit': 'sum',
    'release_prod_water_edit': 'sum'
})
monthly_trend.plot()
plt.title('Tendencia mensual de derrames (2013-2022)')
plt.ylabel('Volumen derramado (barriles)')
plt.xlabel('Fecha')
plt.grid(True)
plt.show()
        </pre>
        <p>Estas visualizaciones muestran la distribución de derrames por mes, la relación entre volúmenes de petróleo y agua derramada, y la tendencia temporal de los derrames.</p>
    </section>
</body>
</html>