<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>An√°lisis de Derrames de Agua Producida en Texas (2013-2022)</title>
    <style>
      body {
        font-family: "Inter", sans-serif;
        background-color: #f8fafc;
      }
      .nav-link {
        transition: all 0.2s ease-in-out;
        border-left: 3px solid transparent;
      }
      .nav-link.active {
        border-left-color: #3b82f6;
        color: #3b82f6;
        background-color: #eff6ff;
      }
      .chart-container {
        position: relative;
        width: 100%;
        height: 350px;
        max-height: 40vh;
      }
      @media (min-width: 768px) {
        .chart-container {
          height: 400px;
        }
      }
      .stat-card {
        background-color: white;
        border-radius: 0.75rem;
        padding: 1.5rem;
        box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1),
          0 2px 4px -2px rgba(0, 0, 0, 0.1);
        transition: transform 0.2s ease-in-out;
      }
      .stat-card:hover {
        transform: translateY(-5px);
      }
      .method-step {
        position: relative;
        padding-left: 2.5rem;
        padding-bottom: 2rem;
        border-left: 2px solid #e5e7eb;
      }
      .method-step:last-child {
        border-left: 2px solid transparent;
        padding-bottom: 0;
      }
      .method-icon {
        position: absolute;
        left: -1rem;
        top: 0;
        width: 2rem;
        height: 2rem;
        display: flex;
        align-items: center;
        justify-content: center;
        border-radius: 9999px;
        background-color: white;
        border: 2px solid #e5e7eb;
      }
      .form-group {
        margin-bottom: 1.5rem;
      }
      .form-group label {
        display: block;
        margin-bottom: 0.5rem;
        font-weight: 500;
        color: #374151;
      }
      .form-group input,
      .form-group select {
        width: 100%;
        padding: 0.75rem;
        border: 1px solid #d1d5db;
        border-radius: 0.375rem;
        font-size: 1rem;
        transition: border-color 0.2s ease-in-out;
      }
      .form-group input:focus,
      .form-group select:focus {
        outline: none;
        border-color: #3b82f6;
        box-shadow: 0 0 0 3px rgba(59, 130, 246, 0.1);
      }
      .predict-btn {
        background-color: #3b82f6;
        color: white;
        padding: 0.75rem 2rem;
        border: none;
        border-radius: 0.375rem;
        font-size: 1rem;
        font-weight: 500;
        cursor: pointer;
        transition: background-color 0.2s ease-in-out;
      }
      .predict-btn:hover {
        background-color: #2563eb;
      }
      .predict-btn:disabled {
        background-color: #9ca3af;
        cursor: not-allowed;
      }
      .result-card {
        background-color: #f0f9ff;
        border: 1px solid #0ea5e9;
        border-radius: 0.75rem;
        padding: 1.5rem;
        margin-top: 1.5rem;
      }
      .sidebar {
        background-color: #ffffff;
        box-shadow: 2px 0 10px rgba(0, 0, 0, 0.1);
      }
      .main-content {
        background-color: #f8fafc;
      }
      .section-title {
        color: #1e293b;
      }
      .section-content {
        color: #475569;
      }
      .data-table {
        width: 100%;
        border-collapse: collapse;
        margin: 1.5rem 0;
        background-color: white;
        border-radius: 0.5rem;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
      }
      .data-table th,
      .data-table td {
        padding: 0.75rem;
        text-align: left;
        border-bottom: 1px solid #e5e7eb;
      }
      .data-table th {
        background-color: #f8fafc;
        font-weight: 600;
        color: #374151;
      }
      .data-table tr:hover {
        background-color: #f9fafb;
      }
      .figure {
        margin: 2rem 0;
        padding: 1rem;
        background-color: white;
        border-radius: 0.5rem;
        box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
      }
      .figure p {
        font-style: italic;
        color: #6b7280;
        margin-bottom: 0.5rem;
      }
      #chartContainer {
        max-width: auto;           
        margin: auto;
        display: flex;
        justify-content: center;
      }

        #performanceChart {
        display: block;
        margin: auto;
        width: 600px;
        max-width: 1000px;
        height: auto !important;
         }

   
        body { font-family: Arial, sans-serif; margin: 20px; }
        nav { background-color: #f8f8f8; padding: 10px; }
        nav ul { list-style-type: none; padding: 0; }
        nav ul li { display: inline; margin-right: 10px; }
        nav ul li a { text-decoration: none; color: #333; }
        section { margin-bottom: 20px; }
        h1, h2, h3 { color: #333; }
        table { border-collapse: collapse; width: 100%; }
        th, td { border: 1px solid #ddd; padding: 8px; text-align: left; }
        th { background-color: #f2f2f2; }
        img { max-width: 100%; height: auto; }
        .math { font-style: italic; }
    </style>
</head>
<body>
    <nav>
        <h2>Men√∫ del Informe</h2>
        <ul>
            <li><a href="#machine-learning">Entendiendo Machine Learning</a></li>
            <li><a href="#problema">Problema</a></li>
            <li><a href="#introduccion">Introducci√≥n</a></li>
            <li><a href="#objetivos">Objetivos</a></li>
            <li><a href="#resumen">Resumen y M√©tricas</a></li>
            <li><a href="#metodologia">Metodolog√≠a</a></li>
            <li><a href="#experimentacion">Experimentaci√≥n</a></li>
            <li><a href="#resultados">Resultados Clave</a></li>
            <li><a href="#rendimiento">Rendimiento</a></li>
            <li><a href="#discusion">Discusi√≥n</a></li>
            <li><a href="#predicciones">Predicciones</a></li>
            <li><a href="#aplicacion">Aplicaci√≥n Web</a></li>
            <li><a href="#conclusiones">Conclusiones</a></li>
        </ul>
    </nav>

    <header>
        <h1>An√°lisis de Derrames de Agua Producida en Texas (2013-2022)</h1>
        <h2>Un Vistazo Interactivo al Modelo Multitarea</h2>
    </header>

    <section id="machine-learning">
        <h2>Entendiendo Machine Learning</h2>
        <p>El aprendizaje autom√°tico (<em>machine learning</em>) es una rama de la inteligencia artificial que permite a los sistemas aprender patrones a partir de datos sin ser expl√≠citamente programados. En este proyecto, utilizamos t√©cnicas de aprendizaje autom√°tico, espec√≠ficamente regresi√≥n lineal y conceptos relacionados, para analizar los derrames de agua producida. A continuaci√≥n, se explican los fundamentos te√≥ricos clave para comprender el enfoque utilizado.</p>

        <h3>Regresi√≥n Lineal</h3>
        <p>La regresi√≥n lineal es una t√©cnica estad√≠stica utilizada para modelar la relaci√≥n entre una variable dependiente (etiqueta) y una o m√°s variables independientes (caracter√≠sticas). En el contexto del aprendizaje autom√°tico, se utiliza para predecir valores num√©ricos continuos.</p>
        <p>Por ejemplo, supongamos que queremos predecir la eficiencia de combustible de un autom√≥vil (millas por gal√≥n) bas√°ndonos en su peso (en miles de libras). A continuaci√≥n, se muestra un conjunto de datos de ejemplo:</p>
        <table>
            <tr><th>Peso (miles de libras)</th><th>Millas por gal√≥n</th></tr>
            <tr><td>3.5</td><td>18</td></tr>
            <tr><td>3.69</td><td>15</td></tr>
            <tr><td>3.44</td><td>18</td></tr>
            <tr><td>3.43</td><td>16</td></tr>
            <tr><td>4.34</td><td>15</td></tr>
            <tr><td>4.42</td><td>14</td></tr>
            <tr><td>2.37</td><td>24</td></tr>
        </table>
        <p>Figura 1: Gr√°fico de puntos que muestra una tendencia descendente de izquierda a derecha, donde a mayor peso, menor eficiencia de combustible.</p>
        <img src="placeholder_car_data.png" alt="Peso vs. Eficiencia de combustible">

        <h4>Ecuaci√≥n de la Regresi√≥n Lineal</h4>
        <p>La regresi√≥n lineal modela la relaci√≥n entre las variables mediante una l√≠nea recta, definida por la ecuaci√≥n:</p>
        <p class="math">y = mx + b</p>
        <p>Donde:</p>
        <ul>
            <li><span class="math">y</span>: es la variable dependiente (etiqueta, en este caso, millas por gal√≥n).</li>
            <li><span class="math">m</span>: es la pendiente de la l√≠nea, que representa el cambio en <span class="math">y</span> por cada unidad de cambio en <span class="math">x</span>.</li>
            <li><span class="math">x</span>: es la variable independiente (caracter√≠stica, en este caso, peso).</li>
            <li><span class="math">b</span>: es la intersecci√≥n con el eje y (el valor de <span class="math">y</span> cuando <span class="math">x = 0</span>).</li>
        </ul>
        <p>En el aprendizaje autom√°tico, esta ecuaci√≥n se escribe como:</p>
        <p class="math">y' = b + w‚ÇÅx‚ÇÅ</p>
        <p>Donde:</p>
        <ul>
            <li><span class="math">y'</span>: es la predicci√≥n del modelo (etiqueta predicha).</li>
            <li><span class="math">b</span>: es el sesgo (<em>bias</em>), equivalente a la intersecci√≥n con el eje y.</li>
            <li><span class="math">w‚ÇÅ</span>: es el peso (<em>weight</em>) de la caracter√≠stica, equivalente a la pendiente.</li>
            <li><span class="math">x‚ÇÅ</span>: es la caracter√≠stica de entrada.</li>
        </ul>
        <p>Figura 2: Representaci√≥n matem√°tica del modelo lineal.</p>
        <img src="placeholder_linear_equation.png" alt="Ecuaci√≥n de regresi√≥n lineal">
        <p>En nuestro ejemplo, despu√©s de entrenar el modelo, se obtuvo un sesgo de 34 y un peso de -4.6, dando como resultado la ecuaci√≥n <span class="math">y' = 34 - 4.6x‚ÇÅ</span>. Usando esta ecuaci√≥n, un autom√≥vil de 4,000 libras tendr√≠a una eficiencia predicha de 15.6 millas por gal√≥n.</p>
        <p>Figura 3: Gr√°fico con la l√≠nea de mejor ajuste y el punto predicho (4, 15.6).</p>
        <img src="placeholder_best_fit_line.png" alt="L√≠nea de mejor ajuste">

        <h4>Modelos con M√∫ltiples Caracter√≠sticas</h4>
        <p>En casos m√°s complejos, la regresi√≥n lineal puede incluir m√∫ltiples caracter√≠sticas. Por ejemplo, para predecir la eficiencia de combustible, podr√≠amos usar caracter√≠sticas adicionales como:</p>
        <ul>
            <li>Desplazamiento del motor</li>
            <li>Aceleraci√≥n</li>
            <li>N√∫mero de cilindros</li>
            <li>Potencia (caballos de fuerza)</li>
        </ul>
        <p>La ecuaci√≥n para un modelo con m√∫ltiples caracter√≠sticas es:</p>
        <p class="math">y' = b + w‚ÇÅx‚ÇÅ + w‚ÇÇx‚ÇÇ + ... + w‚Çôx‚Çô</p>
        <p>Donde cada <span class="math">w·µ¢</span> representa el peso de la caracter√≠stica <span class="math">x·µ¢</span>.</p>

        <h3>P√©rdida (<em>Loss</em>)</h3>
        <p>La p√©rdida es una m√©trica num√©rica que mide cu√°n err√≥neas son las predicciones de un modelo en comparaci√≥n con los valores reales. El objetivo del entrenamiento es minimizar la p√©rdida. La p√©rdida se visualiza como la distancia entre los valores predichos y los valores reales.</p>
        <p>Figura 4: L√≠neas de p√©rdida que conectan los puntos de datos con el modelo, mostrando la distancia entre los valores reales y predichos.</p>
        <img src="placeholder_loss_lines.png" alt="L√≠neas de p√©rdida">

        <h4>Tipos de P√©rdida</h4>
        <p>En la regresi√≥n lineal, se utilizan principalmente dos tipos de p√©rdida:</p>
        <table>
            <tr><th>Tipo de P√©rdida</th><th>Definici√≥n</th><th>Ecuaci√≥n</th></tr>
            <tr><td>P√©rdida L1</td><td>Suma de los valores absolutos de la diferencia entre los valores predichos y reales.</td><td class="math">L1 = |y - y'|</td></tr>
            <tr><td>Error Absoluto Medio (MAE)</td><td>Promedio de las p√©rdidas L1 sobre un conjunto de N ejemplos.</td><td class="math">MAE = (1/N) * Œ£|y - y'|</td></tr>
            <tr><td>P√©rdida L2</td><td>Suma de las diferencias al cuadrado entre los valores predichos y reales.</td><td class="math">L2 = (y - y')¬≤</td></tr>
            <tr><td>Error Cuadr√°tico Medio (MSE)</td><td>Promedio de las p√©rdidas L2 sobre un conjunto de N ejemplos.</td><td class="math">MSE = (1/N) * Œ£(y - y')¬≤</td></tr>
        </table>
        <p>La diferencia principal entre L1 y L2 (o MAE y MSE) es que L2 penaliza m√°s los errores grandes al elevarlos al cuadrado, mientras que L1 trata todos los errores de manera lineal.</p>
        <p>Ejemplo de c√°lculo de p√©rdida L2: Si el modelo predice 23.1 millas por gal√≥n para un autom√≥vil de 2,370 libras, pero el valor real es 26 millas por gal√≥n, la p√©rdida L2 se calcula como:</p>
        <p class="math">L2 = (26 - 23.1)¬≤ = 8.41</p>

        <h4>Elecci√≥n de la P√©rdida</h4>
        <p>La elecci√≥n entre MAE y MSE depende del conjunto de datos y de c√≥mo se deseen manejar los valores at√≠picos (<em>outliers</em>). MSE penaliza m√°s los errores grandes, lo que hace que el modelo se ajuste m√°s a los valores at√≠picos. MAE, por otro lado, es menos sensible a los valores at√≠picos, lo que resulta en un modelo que se ajusta mejor a la mayor√≠a de los datos.</p>
        <p>Figura 5: Modelo entrenado con MSE, m√°s cercano a los valores at√≠picos.</p>
        <img src="placeholder_mse_model.png" alt="Modelo entrenado con MSE">
        <p>Figura 6: Modelo entrenado con MAE, m√°s alejado de los valores at√≠picos.</p>
        <img src="placeholder_mae_model.png" alt="Modelo entrenado con MAE">

        <h3>Descenso por Gradiente</h3>
        <p>El descenso por gradiente es una t√©cnica matem√°tica que ajusta iterativamente los pesos y el sesgo del modelo para minimizar la p√©rdida. El proceso consiste en:</p>
        <ol>
            <li>Iniciar con pesos y sesgo aleatorios cercanos a cero.</li>
            <li>Calcular la p√©rdida con los pesos y sesgo actuales.</li>
            <li>Determinar la direcci√≥n que reduce la p√©rdida (usando el gradiente).</li>
            <li>Actualizar los pesos y el sesgo en peque√±os incrementos en esa direcci√≥n.</li>
            <li>Repetir hasta que la p√©rdida no pueda reducirse m√°s (convergencia).</li>
        </ol>
        <p>Figura 7: Ilustraci√≥n del proceso de descenso por gradiente.</p>
        <img src="placeholder_gradient_descent.png" alt="Descenso por gradiente">

        <h4>Curvas de P√©rdida y Convergencia</h4>
        <p>Una curva de p√©rdida muestra c√≥mo cambia la p√©rdida a medida que el modelo entrena. Una curva t√≠pica muestra una disminuci√≥n r√°pida al inicio, seguida de una estabilizaci√≥n cuando el modelo converge.</p>
        <p>Figura 8: Curva de p√©rdida que muestra convergencia alrededor de la iteraci√≥n 1,000.</p>
        <img src="placeholder_loss_curve.png" alt="Curva de p√©rdida">
        <p>Figura 9: Instant√°neas del modelo en diferentes etapas del entrenamiento, mostrando c√≥mo mejora con el tiempo.</p>
        <img src="placeholder_training_snapshots.png" alt="Instant√°neas del entrenamiento">

        <h4>Superficie de P√©rdida Convexa</h4>
        <p>En la regresi√≥n lineal, la superficie de p√©rdida es siempre convexa, lo que garantiza que el descenso por gradiente encuentre el m√≠nimo global. La figura siguiente muestra una superficie de p√©rdida para un modelo con una caracter√≠stica:</p>
        <p>Figura 10: Superficie de p√©rdida convexa con el m√≠nimo en (peso = -5.44, sesgo = 35.94, p√©rdida = 5.54).</p>
        <img src="placeholder_loss_surface.png" alt="Superficie de p√©rdida">

        <h3>Hiperpar√°metros</h3>
        <p>Los hiperpar√°metros son variables que controlan el proceso de entrenamiento, a diferencia de los par√°metros (pesos y sesgo) que el modelo calcula. Los principales hiperpar√°metros son:</p>

        <h4>Tasa de Aprendizaje (<em>Learning Rate</em>)</h4>
        <p>La tasa de aprendizaje determina el tama√±o de los ajustes a los pesos y el sesgo en cada iteraci√≥n. Una tasa demasiado baja hace que el modelo converja lentamente, mientras que una tasa demasiado alta puede hacer que el modelo no converja. La figura siguiente muestra el impacto de diferentes tasas de aprendizaje:</p>
        <p>Figura 11: Curva de p√©rdida con una tasa de aprendizaje ideal.</p>
        <img src="placeholder_ideal_lr.png" alt="Tasa de aprendizaje ideal">
        <p>Figura 12: Curva de p√©rdida con una tasa de aprendizaje demasiado baja.</p>
        <img src="placeholder_low_lr.png" alt="Tasa de aprendizaje baja">
        <p>Figura 13: Curva de p√©rdida con una tasa de aprendizaje demasiado alta.</p>
        <img src="placeholder_high_lr.png" alt="Tasa de aprendizaje alta">

        <h4>Tama√±o del Lote (<em>Batch Size</em>)</h4>
        <p>El tama√±o del lote determina cu√°ntos ejemplos procesa el modelo antes de actualizar los pesos y el sesgo. Las opciones incluyen:</p>
        <ul>
            <li><strong>Descenso por gradiente estoc√°stico (SGD):</strong> Usa un solo ejemplo por iteraci√≥n, lo que introduce ruido en la curva de p√©rdida.</li>
            <li><strong>Descenso por gradiente de mini-lotes:</strong> Usa un subconjunto de ejemplos, equilibrando ruido y eficiencia.</li>
        </ul>
        <p>Figura 14: Curva de p√©rdida con SGD, mostrando ruido.</p>
        <img src="placeholder_sgd_loss.png" alt="Curva de p√©rdida SGD">
        <p>Figura 15: Curva de p√©rdida con mini-lotes, con menos ruido.</p>
        <img src="placeholder_minibatch_loss.png" alt="Curva de p√©rdida mini-lotes">

        <h4>√âpocas (<em>Epochs</em>)</h4>
        <p>Una √©poca ocurre cuando el modelo ha procesado todos los ejemplos del conjunto de datos una vez. El n√∫mero de √©pocas es un hiperpar√°metro que afecta el tiempo de entrenamiento y la calidad del modelo.</p>
        <p>Figura 16: Comparaci√≥n entre lote completo, mini-lotes y √©pocas.</p>
        <img src="placeholder_batch_epoch.png" alt="Lote vs. √âpocas">
    </section>

    <section id="problema">
        <h2>1. Problem Statement</h2>
        <p>Este proyecto analiza los derrames de agua producida reportados por la industria del petr√≥leo y gas en Texas entre 2013 y 2022. Los datos provienen de informes oficiales de la Comisi√≥n de Ferrocarriles de Texas (RRC), detallando m√°s de 10,000 incidentes durante este per√≠odo. El conjunto de datos incluye variables como la fecha del derrame, el nombre del operador, el condado de ocurrencia, el tipo de operaci√≥n, la fuente y la causa probable del derrame, y los vol√∫menes derramados y recuperados.</p>
        <p>El agua producida contiene sustancias t√≥xicas como metales pesados, residuos de hidrocarburos y qu√≠micos utilizados en la fracturaci√≥n hidr√°ulica, lo que representa una amenaza significativa para el medio ambiente y la salud p√∫blica. Este an√°lisis busca entender la magnitud, recurrencia y distribuci√≥n espacial de tales incidentes para identificar zonas cr√≠ticas, evaluar la responsabilidad del operador y proponer estrategias de gesti√≥n ambiental m√°s efectivas.</p>
    </section>

    <section id="introduccion">
        <h2>2. Introducci√≥n</h2>
        <p>El agua producida representa riesgos ambientales y de salud significativos cuando no se gestiona adecuadamente. En Texas, se reportaron m√°s de 10,000 derrames totalizando m√°s de 148 millones de galones entre 2013 y 2022; solo alrededor del 40% de ese volumen fue recuperado, dejando el resto para impactar el suelo, el agua y los ecosistemas. El agua producida puede contener toxinas como benceno, metales pesados, radio y salinidad elevada, que se han relacionado con la degradaci√≥n del suelo, la p√©rdida de vegetaci√≥n, la mortalidad de la vida silvestre y la contaminaci√≥n de acu√≠feros.</p>
        <p>Figura 17: Visualizaci√≥n geogr√°fica de derrames de agua producida en Texas usando QGIS.</p>
        <img src="placeholder_qgis_map.png" alt="Visualizaci√≥n geogr√°fica de derrames">
    </section>

    <section id="objetivos">
        <h2>3. Objetivos</h2>
        <h3>3.1 Objetivo General</h3>
        <p>Desarrollar un modelo multitarea basado en Keras que prediga simult√°neamente el volumen de agua producida derramada y su causa probable, utilizando Optuna para la optimizaci√≥n de hiperpar√°metros.</p>
        <h3>3.2 Objetivos Espec√≠ficos</h3>
        <ul>
            <li>Preprocesar el conjunto de datos utilizando transformaciones logar√≠tmicas, codificaci√≥n one-hot y divisi√≥n de fechas.</li>
            <li>Dise√±ar una arquitectura neuronal con capas ocultas compartidas y cabezales separados para regresi√≥n y clasificaci√≥n.</li>
            <li>Optimizar los hiperpar√°metros del modelo mediante Optuna en variables arquitect√≥nicas y de entrenamiento.</li>
            <li>Evaluar utilizando R¬≤, MAE, MSE y Accuracy.</li>
            <li>Automatizar la identificaci√≥n y reutilizaci√≥n de la mejor configuraci√≥n para el despliegue.</li>
        </ul>
    </section>

    <section id="resumen">
        <h2>4. Resumen y M√©tricas Clave</h2>
        <p>Esta aplicaci√≥n presenta un modelo de red neuronal dise√±ado para una doble tarea: predecir el volumen de agua derramada (regresi√≥n) y su causa probable (clasificaci√≥n). Mediante la optimizaci√≥n autom√°tica con Optuna, el modelo logra un rendimiento prometedor, demostrando el potencial de los enfoques multitarea en contextos industriales complejos. A continuaci√≥n se presentan los resultados finales m√°s importantes.</p>
        <ul>
            <li><strong>Coeficiente R¬≤ (Volumen):</strong> 0.347</li>
            <li><strong>Precisi√≥n (Causa):</strong> 49.8%</li>
            <li><strong>Error Absoluto Medio:</strong> 1.279</li>
            <li><strong>Error Cuadr√°tico Medio:</strong> 2.764</li>
        </ul>
    </section>

    <section id="metodologia">
        <h2>5. Metodolog√≠a Interactiva</h2>
        <p>El modelo fue construido siguiendo un flujo de trabajo automatizado que va desde el preprocesamiento de los datos hasta la optimizaci√≥n de la arquitectura de la red neuronal. Este enfoque asegura la reproducibilidad y facilita la mejora continua del sistema.</p>
        <h3>5.1 Preparaci√≥n de Datos</h3>
        <ul>
            <li><strong>Valores faltantes:</strong> imputados utilizando la mediana y marcadores de posici√≥n 'Desconocido'.</li>
            <li><strong>Transformaci√≥n logar√≠tmica:</strong> aplicada a los vol√∫menes de derrame para manejar la asimetr√≠a.</li>
            <li><strong>Codificaci√≥n:</strong> variables categ√≥ricas codificadas one-hot; fechas divididas en a√±o/mes.</li>
            <li><strong>Escalado:</strong> caracter√≠sticas normalizadas utilizando MinMaxScaler.</li>
        </ul>
        <p><strong>üìä 1. Preprocesamiento de Datos</strong></p>
        <p>Se utiliz√≥ un conjunto de datos real de derrames. Las variables categ√≥ricas (operador, condado, causa, etc.) fueron transformadas con OneHotEncoder, mientras que a la variable objetivo de volumen se le aplic√≥ una transformaci√≥n logar√≠tmica para estabilizar la varianza.</p>
        <p><strong>üß† 2. Modelo de Red Neuronal Multitarea</strong></p>
        <p>El n√∫cleo del sistema es una red neuronal con capas compartidas que aprenden caracter√≠sticas comunes de los datos. El modelo se bifurca en dos salidas especializadas:</p>
        <ul>
            <li><strong>Salida de Regresi√≥n:</strong> Una capa densa con activaci√≥n lineal para predecir el volumen del derrame.</li>
            <li><strong>Salida de Clasificaci√≥n:</strong> Una capa densa con activaci√≥n Softmax para predecir la probabilidad de cada causa posible.</li>
        </ul>
        <p><strong>‚öôÔ∏è 3. Optimizaci√≥n con Optuna</strong></p>
        <p>Para encontrar la mejor configuraci√≥n, se us√≥ Optuna, un framework de optimizaci√≥n bayesiana que ajust√≥ autom√°ticamente los siguientes hiperpar√°metros clave para minimizar la p√©rdida combinada del modelo:</p>
        <ul>
            <li>Capas</li>
            <li>Neuronas</li>
            <li>Dropout</li>
            <li>Regularizaci√≥n L2</li>
            <li>Tasa de Aprendizaje</li>
            <li>Optimizador</li>
            <li>Tama√±o de Lote</li>
        </ul>
    </section>

    <section id="experimentacion">
        <h2>6. Experimentaci√≥n y Resultados</h2>
        <h3>6.1 Plataforma Computacional</h3>
        <p>El desarrollo del modelo sigui√≥ un flujo de trabajo computacional estructurado. El prototipado inicial se realiz√≥ en el IDE Spyder, donde se dise√±aron y probaron versiones tempranas de la red neuronal utilizando muestras peque√±as de datos y arquitecturas simplificadas. Una vez definida la arquitectura central, el proyecto migr√≥ a Google Colab para aprovechar su aceleraci√≥n gratuita de GPU.</p>
        <h3>6.2 An√°lisis de Rendimiento del Modelo</h3>
        <p>Esta secci√≥n detalla el rendimiento de la red neuronal multitarea en varias m√©tricas para la predicci√≥n del volumen de derrame (regresi√≥n) y la causa del derrame (clasificaci√≥n).</p>
        <h4>P√©rdida Total</h4>
        <table>
            <tr><th>√âpoca</th><th>P√©rdida de Entrenamiento</th><th>P√©rdida de Validaci√≥n</th><th>Diferencia</th></tr>
            <tr><td>1</td><td>62.2842</td><td>45.1358</td><td>17.1484</td></tr>
            <tr><td>6</td><td>7.2674</td><td>4.8145</td><td>2.4529</td></tr>
            <tr><td>11</td><td>5.6395</td><td>4.6213</td><td>1.0182</td></tr>
            <tr><td>16</td><td>4.9681</td><td>4.6037</td><td>0.3645</td></tr>
            <tr><td>21</td><td>4.5250</td><td>4.6631</td><td>0.1382</td></tr>
            <tr><td>26</td><td>4.3510</td><td>4.6861</td><td>0.3352</td></tr>
            <tr><td>27</td><td>4.2380</td><td>4.7025</td><td>0.4644</td></tr>
        </table>
        <p>Figura 18: P√©rdida total de entrenamiento y validaci√≥n por √©poca.</p>
        <img src="placeholder_loss_plot.png" alt="P√©rdida total por √©poca">
        <h4>Precisi√≥n de Clasificaci√≥n</h4>
        <table>
            <tr><th>√âpoca</th><th>Precisi√≥n de Entrenamiento</th><th>Precisi√≥n de Validaci√≥n</th><th>Diferencia</th></tr>
            <tr><td>1</td><td>0.0726</td><td>0.0145</td><td>0.0581</td></tr>
            <tr><td>6</td><td>0.4658</td><td>0.4939</td><td>0.0281</td></tr>
            <tr><td>11</td><td>0.4837</td><td>0.4982</td><td>0.0145</td></tr>
            <tr><td>16</td><td>0.4930</td><td>0.5012</td><td>0.0082</td></tr>
            <tr><td>21</td><td>0.4988</td><td>0.4952</td><td>0.0036</td></tr>
            <tr><td>26</td><td>0.4989</td><td>0.5024</td><td>0.0035</td></tr>
            <tr><td>27</td><td>0.5032</td><td>0.5036</td><td>0.0005</td></tr>
        </table>
        <p>Figura 19: Precisi√≥n de clasificaci√≥n de entrenamiento y validaci√≥n por √©poca.</p>
        <img src="placeholder_accuracy_plot.png" alt="Precisi√≥n por √©poca">
        <h4>MAE de Regresi√≥n (Error Absoluto Medio)</h4>
        <table>
            <tr><th>√âpoca</th><th>MAE de Entrenamiento</th><th>MAE de Validaci√≥n</th><th>Diferencia</th></tr>
            <tr><td>1</td><td>7.1658</td><td>6.0034</td><td>1.1624</td></tr>
            <tr><td>6</td><td>1.8600</td><td>1.3799</td><td>0.4801</td></tr>
            <tr><td>11</td><td>1.5793</td><td>1.3305</td><td>0.2488</td></tr>
            <tr><td>16</td><td>1.4395</td><td>1.3250</td><td>0.1146</td></tr>
            <tr><td>21</td><td>1.3427</td><td>1.3326</td><td>0.0102</td></tr>
            <tr><td>26</td><td>1.3003</td><td>1.3313</td><td>0.0310</td></tr>
            <tr><td>27</td><td>1.2843</td><td>1.3365</td><td>0.0522</td></tr>
        </table>
        <p>Figura 20: MAE de regresi√≥n de entrenamiento y validaci√≥n por √©poca.</p>
        <img src="placeholder_mae_plot.png" alt="MAE por √©poca">
        <h4>MSE de Regresi√≥n (Error Cuadr√°tico Medio)</h4>
        <table>
            <tr><th>√âpoca</th><th>MSE de Entrenamiento</th><th>MSE de Validaci√≥n</th><th>Diferencia</th></tr>
            <tr><td>1</td><td>106.2713</td><td>89.1004</td><td>17.1709</td></tr>
            <tr><td>6</td><td>7.8123</td><td>5.7045</td><td>2.1078</td></tr>
            <tr><td>11</td><td>6.4232</td><td>5.2283</td><td>1.1949</td></tr>
            <tr><td>16</td><td>5.5246</td><td>5.1487</td><td>0.3759</td></tr>
            <tr><td>21</td><td>5.1062</td><td>5.1610</td><td>0.0548</td></tr>
            <tr><td>26</td><td>4.9517</td><td>5.1889</td><td>0.2372</td></tr>
            <tr><td>27</td><td>4.8493</td><td>5.2098</td><td>0.3605</td></tr>
        </table>
    </section>

    <section id="resultados">
        <h2>Resultados Clave</h2>
        <p>Visualizaci√≥n de regresi√≥n y clasificaci√≥n sobre datos reales.</p>
        <h3>Predicci√≥n de Volumen</h3>
        <p>El modelo predice el volumen de agua derramada con un R¬≤ de 0.347 y un MAE de 1.279, indicando una capacidad moderada para capturar la variabilidad en los vol√∫menes de derrame.</p>
        <h3>Predicci√≥n de Causa</h3>
        <p>La precisi√≥n de clasificaci√≥n alcanz√≥ el 49.8%, con las causas m√°s comunes identificadas como fallos mec√°nicos y corrosi√≥n.</p>
    </section>

    <section id="rendimiento">
        <h2>Explorador de Rendimiento</h2>
        <p>Explora c√≥mo evolucionaron las m√©tricas a lo largo de las √©pocas de entrenamiento.</p>
        <ul>
            <li><strong>P√©rdida Total:</strong> La p√©rdida total disminuy√≥ significativamente en las primeras √©pocas, estabiliz√°ndose alrededor de 4.2-4.7.</li>
            <li><strong>Precisi√≥n:</strong> La precisi√≥n de clasificaci√≥n mejor√≥ hasta alcanzar un m√°ximo de 0.5297 en la √©poca 31.</li>
            <li><strong>MAE:</strong> El MAE de regresi√≥n se redujo a 1.2843 en entrenamiento y 1.3365 en validaci√≥n en la √©poca 27.</li>
        </ul>
        <h3>An√°lisis de Datos</h3>
        <p>El an√°lisis de datos revel√≥ patrones significativos:</p>
        <ul>
            <li><strong>Causas principales de derrames:</strong></li>
            <table>
                <tr><th>Causa</th><th>Conteo</th><th>Volumen de Petr√≥leo Derramado (barriles)</th><th>Volumen de Agua Producida Derramada (barriles)</th></tr>
                <tr><td>CORROSION</td><td>259</td><td>-</td><td>-</td></tr>
                <tr><td>MECHANICAL FAILURE</td><td>183</td><td>-</td><td>-</td></tr>
                <tr><td>WEATHER</td><td>47</td><td>-</td><td>-</td></tr>
                <tr><td>HUMAN ERROR</td><td>39</td><td>-</td><td>-</td></tr>
                <tr><td>THEFT / VANDALISM</td><td>1</td><td>-</td><td>-</td></tr>
            </table>
            <li><strong>An√°lisis por operador (ejemplo: APACHE):</strong></li>
            <table>
                <tr><th>M√©trica</th><th>Valor</th></tr>
                <tr><td>Total derrames</td><td>287</td></tr>
                <tr><td>Petr√≥leo total derramado</td><td>437312.40 barriles</td></tr>
                <tr><td>Agua producida total derramada</td><td>6307518.00 barriles</td></tr>
            </table>
            <li><strong>An√°lisis por condado (ejemplo: Andrews):</strong></li>
            <table>
                <tr><th>M√©trica</th><th>Valor</th></tr>
                <tr><td>Total derrames</td><td>529</td></tr>
                <tr><td>Petr√≥leo total derramado</td><td>365615.21 barriles</td></tr>
                <tr><td>Agua producida total derramada</td><td>6746821.12 barriles</td></tr>
            </table>
        </ul>
        <h3>Visualizaciones</h3>
        <p>Se generaron varias visualizaciones para explorar los datos:</p>
        <ul>
            <li><strong>Derrames por mes:</strong> Gr√°fico de l√≠neas mostrando la tendencia mensual de derrames.</li>
            <li><strong>Relaci√≥n petr√≥leo vs agua:</strong> Gr√°fico de dispersi√≥n logar√≠tmico.</li>
            <li><strong>Derrames en agua vs tierra:</strong> Gr√°fico de barras.</li>
            <li><strong>Gr√°fico 3D:</strong> Visualizaci√≥n de derrames por a√±o, mes y volumen logar√≠tmico.</li>
        </ul>
    </section>

    <section id="discusion">
        <h2>7. Discusi√≥n</h2>
        <p>A pesar de las limitaciones en la precisi√≥n de las predicciones, los resultados muestran una clara tendencia hacia la mejora del modelo con el aumento de datos y la optimizaci√≥n. El desempe√±o de la regresi√≥n (R¬≤ ‚âà 0.35) y clasificaci√≥n (‚âà 50%) sugiere que el enfoque multitarea puede capturar patrones √∫tiles incluso en conjuntos de datos con ruido e incertidumbre.</p>
        <p>Se identificaron operadores y condados con altas tasas de derrames, lo que puede guiar intervenciones regulatorias. Adem√°s, la causa m√°s com√∫n de los derrames fue el fallo de equipos, destacando la necesidad de mantenimiento preventivo en infraestructura.</p>
    </section>

    <section id="predicciones">
        <h2>Predicciones</h2>
        <p>El modelo predice tanto el volumen de agua derramada como la causa probable. Ejemplo de predicciones:</p>
        <table>
            <tr><th>PREDICTED_LOG_WATER</th><th>OBSERVED_LOG_WATER</th><th>L1_LOSS_WATER</th><th>PREDICTED_CAUSE</th></tr>
            <tr><td>9.30</td><td>8.34</td><td>0.96</td><td>CORROSION</td></tr>
            <tr><td>8.25</td><td>6.73</td><td>1.52</td><td>MECHANICAL FAILURE</td></tr>
            <tr><td>7.31</td><td>4.44</td><td>2.86</td><td>MECHANICAL FAILURE</td></tr>
            <tr><td>8.54</td><td>6.66</td><td>0.16</td><td>MECHANICAL FAILURE</td></tr>
            <tr><td>7.49</td><td>9.04</td><td>1.56</td><td>MECHANICAL FAILURE</td></tr>
        </table>
    </section>

    <section id="aplicacion">
        <h2>8. Aplicaci√≥n Web</h2>
        <p>Se desarroll√≥ una aplicaci√≥n web interactiva que permite cargar datos y predecir en tiempo real tanto el volumen estimado de agua derramada como su causa probable. Esta herramienta puede ser utilizada por reguladores, investigadores y operadores para monitorear riesgos y responder de forma proactiva.</p>
        <h3>Interfaz de Predicciones</h3>
        <p>La aplicaci√≥n incluye dropdowns para seleccionar valores de entrada (a√±o, mes, operador, condado, tipo de operaci√≥n, fuente) y un bot√≥n para ejecutar predicciones. Ejemplo de uso:</p>
        <pre>
# Ejemplo de c√≥digo para la interfaz de predicciones
import pandas as pd
import numpy as np
import tensorflow as tf
import joblib
import os
from IPython.display import display
import ipywidgets as widgets
from tensorflow.keras.models import load_model
from tensorflow.keras.metrics import MeanSquaredError

def format_currency(x):
    return "{:.2f}".format(x)

def predict_outcomes(model, df, features, le_causa, preprocessor, batch_size=1):
    batch = df.copy()
    batch.set_index(np.arange(len(batch)), inplace=True)
    X_batch = preprocessor.transform(batch[features])
    predictions = model.predict(X_batch, verbose=0)
    y_reg_pred = predictions[0].flatten()
    y_clf_pred = np.argmax(predictions[1], axis=1)
    data = {
        "PREDICTED_WATER": [format_currency(np.expm1(y)) for y in y_reg_pred],
        "PREDICTED_CAUSE": [le_causa.inverse_transform([y])[0] for y in y_clf_pred]
    }
    return pd.DataFrame(data)

def show_predictions(output):
    header = "\n" + "="*50 + "\n" + "| " + "PREDICCIONES".center(48) + " |\n" + "="*50
    print(header)
    for _, row in output.iterrows():
        print(f"Cantidad Derramada: {row['PREDICTED_WATER']} barriles")
        print(f"Causa Probable: {row['PREDICTED_CAUSE']}")

def load_required_files():
    try:
        required_files = ["spill_data_cleaned.csv", "modelo_trained.h5", "preprocessor.pkl", "labelencoder_causa.pkl"]
        missing_files = [f for f in required_files if not os.path.exists(f)]
        if missing_files:
            print(f"Archivos faltantes: {missing_files}")
            return None, None, None, None
        model = load_model("modelo_trained.h5", custom_objects={"mse": MeanSquaredError()})
        preprocessor = joblib.load("preprocessor.pkl")
        le_causa = joblib.load("labelencoder_causa.pkl")
        df = pd.read_csv("spill_data_cleaned.csv", sep=",", encoding="latin-1")
        return model, preprocessor, le_causa, df
    except Exception as e:
        print(f"Error cargando archivos: {e}")
        return None, None, None, None

def get_unique_values(df, column):
    unique_values = df[column].astype(str).str.strip().unique()
    return sorted([x for x in unique_values if str(x).lower() != 'nan'])

def create_dropdowns(df, model, preprocessor, le_causa):
    features = ['year', 'month', 'operator_edit', 'county_edit', 'type_operation', 'source']
    year_dropdown = widgets.Dropdown(options=get_unique_values(df, 'year'), description='A√±o:')
    month_dropdown = widgets.Dropdown(options=get_unique_values(df, 'month'), description='Mes:')
    operator_dropdown = widgets.Dropdown(options=get_unique_values(df, 'operator_edit'), description='Operador:')
    county_dropdown = widgets.Dropdown(options=get_unique_values(df, 'county_edit'), description='Condado:')
    type_operation_dropdown = widgets.Dropdown(options=get_unique_values(df, 'type_operation'), description='Operaci√≥n:')
    source_dropdown = widgets.Dropdown(options=get_unique_values(df, 'source'), description='Fuente:')
    predict_button = widgets.Button(description="Hacer Predicci√≥n", button_style='success', tooltip='Click para hacer predicci√≥n')
    output = widgets.Output()

    def on_predict_button_clicked(b):
        with output:
            output.clear_output()
            if model is None or preprocessor is None or le_causa is None:
                print("Error: Modelo, preprocesador o codificador de etiquetas no cargados")
                return
            input_data = {
                'year': [year_dropdown.value],
                'month': [month_dropdown.value],
                'operator_edit': [operator_dropdown.value],
                'county_edit': [county_dropdown.value],
                'type_operation': [type_operation_dropdown.value],
                'source': [source_dropdown.value]
            }
            input_df = pd.DataFrame(input_data)
            try:
                pred_df = predict_outcomes(model, input_df, features, le_causa, preprocessor, batch_size=1)
                show_predictions(pred_df)
            except Exception as e:
                print(f"Error al hacer predicci√≥n: {e}")

    predict_button.on_click(on_predict_button_clicked)
    display(widgets.VBox([year_dropdown, month_dropdown, operator_dropdown, county_dropdown, type_operation_dropdown, source_dropdown, predict_button, output]))

def main():
    print("Iniciando script de predicci√≥n con dropdowns...")
    model, preprocessor, le_causa, df = load_required_files()
    if model is None or preprocessor is None or le_causa is None or df is None:
        print("No se pudieron cargar los archivos necesarios. Terminando ejecuci√≥n.")
        return
    print("Archivos cargados correctamente. Selecciona los valores para la predicci√≥n.")
    create_dropdowns(df, model, preprocessor, le_causa)

if __name__ == "__main__":
    main()
        </pre>
    </section>

    <section id="conclusiones">
        <h2>9. Conclusiones</h2>
        <p>Este proyecto demuestra el potencial de la inteligencia artificial para abordar problemas ambientales complejos. El modelo multitarea logr√≥ resultados competitivos en la predicci√≥n de variables clave, y su integraci√≥n con una interfaz web proporciona un sistema pr√°ctico para usuarios no t√©cnicos.</p>
        <p>Como futuras mejoras, se plantea incrementar el volumen de datos, refinar el tratamiento de valores at√≠picos y explorar arquitecturas m√°s sofisticadas como redes recurrentes o transformers para aprovechar patrones temporales m√°s complejos.</p>
    </section>

    <section id="codigo">
        <h2>10. C√≥digo y Detalles T√©cnicos</h2>
        <h3>10.1 Instalaci√≥n de Optuna</h3>
        <pre>
pip install optuna
# Salida: Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)
# Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.4)
# Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna)...
        </pre>
        <p>El comando ejecuta la instalaci√≥n de la librer√≠a Optuna, una herramienta de optimizaci√≥n de hiperpar√°metros para modelos de aprendizaje autom√°tico. Se utiliza desde la l√≠nea de comandos en un entorno con Python y pip instalados.</p>

        <h3>10.2 Configuraci√≥n del Entorno</h3>
        <pre>
import pandas as pd
import numpy as np
import json
import os
import optuna
import matplotlib.pyplot as plt
import tensorflow as tf
import warnings
import base64
import requests
import re
import joblib
from datetime import datetime
from sklearn.model_selection import train_test_split
from tensorflow.keras.optimizers import Adam, RMSprop, SGD
from tensorflow.keras.regularizers import l2
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
        </pre>
        <p>Este c√≥digo importa las librer√≠as necesarias para el modelado, incluyendo pandas para manipulaci√≥n de datos, numpy para c√°lculos num√©ricos, tensorflow para redes neuronales, y optuna para optimizaci√≥n de hiperpar√°metros.</p>

        <h3>10.3 Preprocesamiento de Datos</h3>
        <pre>
df = pd.read_csv("spill_data_cleaned.csv", sep=';', encoding='latin-1')
df = df.dropna(subset=['release_prod_water_edit'])
df['log_release_prod_water_edit'] = np.log10(df['release_prod_water_edit'])
cat_cols = ['operator_edit', 'county_edit', 'type_operation', 'source', 'probable_cause_edit']
for col in cat_cols:
    df[col] = df[col].fillna('unknown').astype(str).str.lower()
df['date'] = pd.to_datetime(df['date_of_spill_edit'])
df['month'] = df['date'].dt.month
df['year'] = df['date'].dt.year
df.drop(columns=['date'], inplace=True)
y_reg = df['log_release_prod_water_edit']
y_clf = df['probable_cause_edit']
X = df[['year', 'month', 'operator_edit', 'county_edit', 'type_operation', 'source']]
num_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
cat_features = X.select_dtypes(include=['object']).columns.tolist()
preprocessor = ColumnTransformer(transformers=[
    ('num', StandardScaler(), num_features),
    ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)
])
X_processed = preprocessor.fit_transform(X)
        </pre>
        <p>Este c√≥digo carga el conjunto de datos, elimina valores nulos, aplica transformaci√≥n logar√≠tmica a los vol√∫menes de agua derramada, codifica variables categ√≥ricas y normaliza las caracter√≠sticas num√©ricas.</p>

        <h3>10.4 Generaci√≥n de Gr√°ficos</h3>
        <pre>
def make_plots(df, feature_names, label_name, model_output, sample_size=200):
    random_sample = df.sample(n=sample_size).copy()
    random_sample.reset_index(drop=True, inplace=True)
    weights, bias, epochs, metrics = model_output
    is_2d_plot = len(feature_names) == 1
    # C√≥digo para generar gr√°ficos 2D/3D con Plotly
def plot_data(df, features, label, fig):
    if len(features) == 1:
        scatter = px.scatter(df, x=features[0], y=label, color=df['probable_cause_edit'])
    else:
        scatter = px.scatter_3d(df, x=features[0], y=features[1], z=label, color=df['probable_cause_edit'])
    fig.add_trace(scatter.data[0], row=1, col=2)
    if len(features) == 1:
        fig.update_xaxes(title_text=features[0], row=1, col=2)
        fig.update_yaxes(title_text=label, row=1, col=2)
    else:
        fig.update_layout(scene=dict(
            xaxis_title=features[0],
            yaxis_title=features[1],
            zaxis_title=label
        ))
def plot_model(df, features, weights, bias, fig):
    df['REG_PREDICTED'] = bias[0]
    for index, feature in enumerate(features):
        df['REG_PREDICTED'] += df[feature] * weights[index][0]
    # C√≥digo para graficar predicciones
def plot_loss_curve(epochs, metric, fig):
    fig.add_trace(go.Scatter(x=epochs, y=metric, mode='lines', name='Loss'))
    fig.update_yaxes(title_text="Classification Accuracy", row=1, col=1, range=[metric.min()*0.8, metric.max()])
        </pre>
        <p>Estas funciones generan visualizaciones 2D y 3D de los datos y las predicciones del modelo utilizando Plotly.</p>

        <h3>10.5 Optimizaci√≥n con Optuna</h3>
        <pre>
def objective(trial):
    n_layers = trial.suggest_int("n_layers", 2, 4)
    dropout_rate = trial.suggest_float("dropout_rate", 0.1, 0.5)
    l2_reg = trial.suggest_float("l2_reg", 1e-6, 1e-2, log=True)
    learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)
    optimizer_name = trial.suggest_categorical('optimizer', ['adam', 'rmsprop'])
    batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])
    use_batch_norm = trial.suggest_categorical('use_batch_norm', [True, False])
    input_layer = Input(shape=(input_dim,))
    x = input_layer
    for i in range(n_layers):
        x = Dense(trial.suggest_int(f'units_{i}', 16, 128))(x)
        if use_batch_norm:
            x = BatchNormalization()(x)
        x = Dropout(dropout_rate)(x)
    regression_output = Dense(1, name='regression')(x)
    classification_output = Dense(num_classes, activation='softmax', name='classification')(x)
    model = Model(inputs=input_layer, outputs=[regression_output, classification_output])
    if optimizer_name == 'adam':
        optimizer = Adam(learning_rate=learning_rate)
    else:
        optimizer = RMSprop(learning_rate=learning_rate)
    model.compile(
        optimizer=optimizer,
        loss={'regression': 'mae', 'classification': 'categorical_crossentropy'},
        loss_weights={'regression': 0.5, 'classification': 0.5},
        metrics={'regression': ['mae'], 'classification': ['accuracy']}
    )
    history = model.fit(
        X_train_opt,
        {'regression': y_reg_train_opt, 'classification': y_clf_train_opt},
        validation_data=(X_val_opt, {'regression': y_reg_val_opt, 'classification': y_clf_val_opt}),
        epochs=30,
        batch_size=batch_size,
        verbose=0
    )
    return history.history['val_loss'][-1]
        </pre>
        <p>Esta funci√≥n define el objetivo de optimizaci√≥n para Optuna, ajustando hiperpar√°metros como el n√∫mero de capas, tasa de dropout, regularizaci√≥n L2, y optimizador.</p>

        <h3>10.6 Guardado y Carga de Par√°metros</h3>
        <pre>
timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
best_params_data = {
    'timestamp': timestamp,
    'best_value': study.best_value,
    'best_params': study.best_params,
    'n_trials': len(study.trials),
    'optimization_complete': True
}
filename = f'best_params_{timestamp}.json'
with open(filename, 'w') as f:
    json.dump(best_params_data, f, indent=2)
print(f"Optimizaci√≥n completada! Mejores par√°metros guardados en: {filename}")

def load_best_params_from_json(json_filename):
    if not os.path.exists(json_filename):
        raise FileNotFoundError(f"El archivo {json_filename} no existe")
    with open(json_filename, 'r') as f:
        data = json.load(f)
    print(f"Archivo: {json_filename}, Timestamp: {data['timestamp']}, Mejor p√©rdida: {data['best_value']:.4f}")
    return data['best_params']

def load_and_compare_all_params(json_files):
    if not json_files:
        print("No se encontraron archivos de par√°metros")
        return None, None
    best_score = -float('inf')
    best_params = None
    best_file = None
    for filename in json_files:
        try:
            with open(filename, 'r') as f:
                data = json.load(f)
            if 'metrics' in data and isinstance(data['metrics'], dict):
                r2 = data['metrics'].get('r2', 0)
                accuracy = data['metrics'].get('accuracy', 0)
                if isinstance(r2, (int, float)) and isinstance(accuracy, (int, float)):
                    score = r2 * 0.6 + accuracy * 0.4
                    score_source = f'metrics (R2: {r2:.3f}, Acc: {accuracy:.3f})'
            elif 'best_value' in data and isinstance(data['best_value'], (int, float)):
                score = -data['best_value']
                score_source = f"Optuna best_value ({data['best_value']})"
            else:
                score = os.path.getmtime(filename)
                score_source = "timestamp (fallback)"
            print(f"{filename}: score {score:.4f} ({score_source})")
            if score > best_score:
                best_score = score
                best_params = data.get('best_params', data)
                best_file = filename
        except Exception as e:
            print(f"Error cargando {filename}: {e}")
    if best_file:
        print(f"Mejor archivo seleccionado: {best_file} (score: {best_score:.4f})")
        return best_file, best_params
    return None, None
        </pre>
        <p>Estas funciones guardan y comparan los mejores par√°metros encontrados por Optuna, seleccionando el mejor modelo basado en m√©tricas o fecha de modificaci√≥n.</p>

        <h3>10.7 Modelo Final y Evaluaci√≥n</h3>
        <pre>
def build_model_from_params(best_params, input_dim, num_classes):
    n_layers = best_params.get('n_layers', 2)
    dropout_rate = best_params.get('dropout_rate', 0.2)
    l2_reg = best_params.get('l2_reg', 1e-4)
    learning_rate = best_params.get('learning_rate', 1e-3)
    optimizer_name = best_params.get('optimizer', 'adam')
    input_layer = Input(shape=(input_dim,))
    x = input_layer
    for i in range(n_layers):
        x = Dense(best_params.get(f'units_{i}', 64), kernel_regularizer=l2(l2_reg))(x)
        x = Dropout(dropout_rate)(x)
    regression_output = Dense(1, name='regression')(x)
    classification_output = Dense(num_classes, activation='softmax', name='classification')(x)
    model = Model(inputs=input_layer, outputs=[regression_output, classification_output])
    if optimizer_name == 'adam':
        optimizer = Adam(learning_rate=learning_rate)
    else:
        optimizer = RMSprop(learning_rate=learning_rate)
    model.compile(
        optimizer=optimizer,
        loss={'regression': 'mse', 'classification': 'categorical_crossentropy'},
        metrics={'regression': ['mae'], 'classification': ['accuracy']}
    )
    return model

model.save("modelo_trained.h5")
joblib.dump(preprocessor, "preprocessor.pkl")
print("Modelo guardado en modelo_trained.h5")
print("Preprocesor guardado en preprocessor.pkl")

test_results = model.evaluate(X_test, {'regression': y_reg_test, 'classification': y_clf_test}, verbose=0)
print(f"Resultados en test: R2: {r2:.4f}, MSE: {mse:.4f}, MAE: {mae:.4f}, Accuracy: {accuracy:.4f}")
        </pre>
        <p>Este c√≥digo construye el modelo final con los mejores par√°metros, lo guarda en disco y eval√∫a su rendimiento en el conjunto de prueba.</p>

        <h3>10.8 Visualizaci√≥n Adicional</h3>
        <pre>
plt.figure(figsize=(15, 10))
plt.subplot(2, 2, 1)
monthly_spills = df.groupby('month').size()
monthly_spills.plot(kind='bar')
plt.title('Derrames por mes')
plt.subplot(2, 2, 2)
plt.scatter(np.log10(df['release_crude_oil_edit']), np.log10(df['release_prod_water_edit']), alpha=0.6)
plt.title('Relaci√≥n entre petr√≥leo y agua producida derramada')
plt.xlabel('Petr√≥leo derramado (barriles) - escala log')
plt.ylabel('Agua producida derramada (barriles) - escala log')
plt.subplot(2, 2, 4)
water_spills = df['spill_on_water_edit'].value_counts()
water_spills.plot(kind='bar', color=['salmon', 'lightgreen'])
plt.title('Derrames en agua vs tierra')
plt.xticks([0, 1], ['Tierra', 'Agua'], rotation=0)
plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 6))
monthly_trend = df.resample('M', on='date_of_spill_edit').agg({
    'release_crude_oil_edit': 'sum',
    'release_prod_water_edit': 'sum'
})
monthly_trend.plot()
plt.title('Tendencia mensual de derrames (2013-2022)')
plt.ylabel('Volumen derramado (barriles)')
plt.xlabel('Fecha')
plt.grid(True)
plt.show()
        </pre>
        <p>Estas visualizaciones muestran la distribuci√≥n de derrames por mes, la relaci√≥n entre vol√∫menes de petr√≥leo y agua derramada, y la tendencia temporal de los derrames.</p>
    </section>
</body>
</html>