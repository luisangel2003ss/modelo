{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luisangel2003ss/modelo/blob/main/cpyWaterSpillOil.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZNSyLFOpLPm"
      },
      "source": [
        "# Notebook: Predicci√≥n multitarea con Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXCudcYqpgh4"
      },
      "source": [
        "# Librer√≠as"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I32VqEN3pGR0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "import optuna\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import warnings\n",
        "import base64\n",
        "import requests\n",
        "import re\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import r2_score, mean_squared_error, accuracy_score\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.regularizers import l2\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "print(os.path.getsize(\"spill_data_cleaned.csv\"))  # Debe mostrar tama√±o > 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"spill_data_cleaned.csv\", sep=';', encoding='latin-1', on_bad_lines='skip', engine='python')\n",
        "\n",
        "# Convertir a min√∫sculas solo las columnas de texto que existen\n",
        "for col in df.select_dtypes(include='object').columns:\n",
        "    df[col] = df[col].astype(str).str.lower()\n",
        "\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ShnuwZONp1zZ"
      },
      "source": [
        "# 1. FUNCION PARA ENTRENAR CON OPTUNA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "15oBqomOp5cY"
      },
      "outputs": [],
      "source": [
        "def run_optuna_optimization(X_train, y_reg_train, y_clf_train, n_trials=150):\n",
        "    \"\"\"\n",
        "    Ejecuta optimizaci√≥n con Optuna y guarda los mejores par√°metros\n",
        "    ESTO SE EJECUTA SOLO UNA VEZ PARA ENCONTRAR LOS MEJORES HIPERPAR√ÅMETROS\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"EJECUTANDO OPTIMIZACI√ìN CON OPTUNA...\")\n",
        "    print(\"Esto puede tomar tiempo pero solo se hace UNA VEZ\")\n",
        "\n",
        "    input_dim = X_train.shape[1]\n",
        "    num_classes = y_clf_train.shape[1]\n",
        "\n",
        "    # Divisi√≥n para validaci√≥n interna\n",
        "    X_train_opt, X_val_opt, y_reg_train_opt, y_reg_val_opt, y_clf_train_opt, y_clf_val_opt = train_test_split(\n",
        "        X_train, y_reg_train, y_clf_train, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    def objective(trial):\n",
        "\n",
        "        # Hiperpar√°metros a optimizar\n",
        "        n_layers = trial.suggest_int('n_layers', 2, 4)\n",
        "        dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n",
        "        l2_reg = trial.suggest_float('l2_reg', 1e-6, 1e-2, log=True)\n",
        "        learning_rate = trial.suggest_float('learning_rate', 1e-5, 1e-2, log=True)\n",
        "        optimizer_name = trial.suggest_categorical('optimizer', ['adam', 'rmsprop'])\n",
        "        batch_size = trial.suggest_categorical('batch_size', [32, 64, 128])\n",
        "        use_batch_norm = trial.suggest_categorical('use_batch_norm', [True, False])\n",
        "\n",
        "        # Construir modelo\n",
        "        input_layer = Input(shape=(input_dim,))\n",
        "        x = input_layer\n",
        "\n",
        "        for i in range(n_layers):\n",
        "            if i == 0:\n",
        "                neurons = trial.suggest_int(f'neurons_layer_{i}', 64, 256)\n",
        "            else:\n",
        "                max_neurons = max(32, int(neurons * 0.7))\n",
        "                neurons = trial.suggest_int(f'neurons_layer_{i}', 32, max_neurons)\n",
        "\n",
        "            x = Dense(neurons, activation='relu', kernel_regularizer=l2(l2_reg))(x)\n",
        "\n",
        "            if use_batch_norm:\n",
        "                x = BatchNormalization()(x)\n",
        "\n",
        "            x = Dropout(dropout_rate)(x)\n",
        "\n",
        "        # Salidas\n",
        "        regression_output = Dense(1, name='regression')(x)\n",
        "        classification_output = Dense(num_classes, activation='softmax', name='classification')(x)\n",
        "\n",
        "        model = Model(inputs=input_layer, outputs=[regression_output, classification_output])\n",
        "\n",
        "        # Configurar optimizador\n",
        "        if optimizer_name == 'adam':\n",
        "            optimizer = Adam(learning_rate=learning_rate)\n",
        "        else:\n",
        "            optimizer = RMSprop(learning_rate=learning_rate)\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss={'regression': 'mae', 'classification': 'categorical_crossentropy'},\n",
        "            loss_weights={'regression': 0.5, 'classification': 0.5}\n",
        "        )\n",
        "\n",
        "        # Entrenar\n",
        "        try:\n",
        "            history = model.fit(\n",
        "                X_train_opt,\n",
        "                {'regression': y_reg_train_opt, 'classification': y_clf_train_opt},\n",
        "                validation_data=(X_val_opt, {'regression': y_reg_val_opt, 'classification': y_clf_val_opt}),\n",
        "                epochs=35,\n",
        "                batch_size=batch_size,\n",
        "                callbacks=[EarlyStopping(patience=5, restore_best_weights=True)],\n",
        "                verbose=0\n",
        "            )\n",
        "\n",
        "            # Evaluar\n",
        "            val_results = model.evaluate(\n",
        "                X_val_opt,\n",
        "                {'regression': y_reg_val_opt, 'classification': y_clf_val_opt},\n",
        "                verbose=0\n",
        "            )\n",
        "\n",
        "            return val_results[0]  # P√©rdida total\n",
        "\n",
        "        except Exception as e:\n",
        "            return float('inf')\n",
        "\n",
        "    # Ejecutar optimizaci√≥n\n",
        "    study = optuna.create_study(direction='minimize')\n",
        "    study.optimize(objective, n_trials=n_trials)\n",
        "\n",
        "    # Guardar mejores par√°metros\n",
        "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "    best_params_data = {\n",
        "        'timestamp': timestamp,\n",
        "        'best_value': study.best_value,\n",
        "        'best_params': study.best_params,\n",
        "        'n_trials': len(study.trials),\n",
        "        'optimization_complete': True\n",
        "    }\n",
        "\n",
        "    filename = f'best_params_{timestamp}.json'\n",
        "    with open(filename, 'w') as f:\n",
        "        json.dump(best_params_data, f, indent=2)\n",
        "\n",
        "    print(f\"Optimizaci√≥n completada!\")\n",
        "    print(f\"Mejores par√°metros guardados en: {filename}\")\n",
        "    print(f\"Mejor p√©rdida: {study.best_value:.4f}\")\n",
        "\n",
        "    return filename, study.best_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xTySuvEaqrj4"
      },
      "source": [
        "# 2. FUNCI√ìN PARA CARGAR PAR√ÅMETROS DESDE JSON"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5h_y3dXqs8x"
      },
      "outputs": [],
      "source": [
        "def load_best_params_from_json(json_filename):\n",
        "    \"\"\"\n",
        "    Carga los mejores par√°metros desde un archivo JSON\n",
        "    ESTO SE USA EN PRODUCCI√ìN - NO NECESITA REOPTIMIZAR\n",
        "    \"\"\"\n",
        "\n",
        "    if not os.path.exists(json_filename):\n",
        "        raise FileNotFoundError(f\"Archivo no encontrado: {json_filename}\")\n",
        "\n",
        "    with open(json_filename, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    print(f\"Cargando par√°metros desde: {json_filename}\")\n",
        "    print(f\"Optimizaci√≥n realizada: {data['timestamp']}\")\n",
        "    print(f\"Mejor p√©rdida obtenida: {data['best_value']:.4f}\")\n",
        "\n",
        "    return data['best_params']\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmerSgrTsJsn"
      },
      "source": [
        "# 3. FUNCI√ìN PARA CONSTRUIR MODELO CON PAR√ÅMETROS DADOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwNM9WHcsOwB"
      },
      "outputs": [],
      "source": [
        "def build_model_from_params(best_params, input_dim, num_classes):\n",
        "    # Extraer par√°metros con valores por defecto si no existen\n",
        "    n_layers = best_params.get('n_layers', 2)\n",
        "    units = best_params.get('units', 64)\n",
        "    dropout_rate = best_params.get('dropout_rate', 0.3)\n",
        "    l2_reg = best_params.get('l2_reg', 1e-4)\n",
        "    learning_rate = best_params.get('learning_rate', 1e-3)\n",
        "\n",
        "    # Construcci√≥n del modelo\n",
        "    inputs = Input(shape=(input_dim,), name=\"input_layer_1\") \n",
        "    x = inputs\n",
        "\n",
        "    for _ in range(n_layers):\n",
        "        x = Dense(units, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(l2_reg))(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(best_params.get('dropout_rate', 0.3))(x)\n",
        "        \n",
        "    # Salidas\n",
        "    regression_output = Dense(1, name='regression')(x)\n",
        "    classification_output = Dense(num_classes, activation='softmax', name='classification')(x)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=[regression_output, classification_output])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate),\n",
        "        loss={\n",
        "            'regression': 'mse',\n",
        "            'classification': 'categorical_crossentropy'\n",
        "        },\n",
        "        metrics={\n",
        "            'regression': ['mae'],\n",
        "            'classification': ['accuracy']\n",
        "        }\n",
        "    )\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhWMrvwgvnLu"
      },
      "source": [
        "# 4. WORKFLOW PRINCIPAL, OPTIMIZAR O USAR PAR√ÅMETROS EXISTENTES?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qOjCMBsjbOJU",
        "outputId": "de484283-22d2-4a98-cb28-b77d5eb7faf7"
      },
      "outputs": [],
      "source": [
        "# ===== CONFIGURACI√ìN =====\n",
        "GITHUB_REPO = \"luisangel2003ss/modelo\"  # Tu repositorio\n",
        "GITHUB_BRANCH = \"main\"  # Rama donde subir\n",
        "\n",
        "# ===== FUNCIONES CORREGIDAS =====\n",
        "def select_best_params_file(json_files):\n",
        "    \"\"\"\n",
        "    Selecciona autom√°ticamente el mejor archivo de par√°metros basado en:\n",
        "    1. Fecha de modificaci√≥n m√°s reciente\n",
        "    2. Si hay archivos con m√©tricas en el nombre, usa el de mejores m√©tricas\n",
        "    \"\"\"\n",
        "    if not json_files:\n",
        "        print(\"‚ö†Ô∏è No se encontraron archivos de par√°metros\")\n",
        "        return None\n",
        "\n",
        "    print(f\"üîç Se encontraron {len(json_files)} archivos de par√°metros:\")\n",
        "\n",
        "    files_with_info = []\n",
        "    for f in json_files:\n",
        "        try:\n",
        "            modification_time = os.path.getmtime(f)\n",
        "            file_size = os.path.getsize(f)\n",
        "\n",
        "            metrics_in_name = None\n",
        "            if 'r2_' in f.lower() or 'acc_' in f.lower():\n",
        "                numbers = re.findall(r'[\\d.]+', f)\n",
        "                if numbers:\n",
        "                    try:\n",
        "                        metrics_in_name = float(numbers[0])\n",
        "                    except ValueError:\n",
        "                        metrics_in_name = None\n",
        "\n",
        "            files_with_info.append({\n",
        "                'filename': f,\n",
        "                'mod_time': modification_time,\n",
        "                'metrics': metrics_in_name,\n",
        "                'size': file_size\n",
        "            })\n",
        "\n",
        "            mod_time_str = pd.to_datetime(modification_time, unit='s').strftime('%Y-%m-%d %H:%M')\n",
        "            metric_str = f\", m√©trica: {metrics_in_name}\" if metrics_in_name else \"\"\n",
        "            print(f\"  üìÑ {f} (modificado: {mod_time_str}, tama√±o: {file_size} bytes{metric_str})\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ö†Ô∏è Error leyendo {f}: {e}\")\n",
        "            files_with_info.append({\n",
        "                'filename': f,\n",
        "                'mod_time': 0,\n",
        "                'metrics': None,\n",
        "                'size': 0\n",
        "            })\n",
        "\n",
        "    valid_files = [f for f in files_with_info if f['size'] > 0]\n",
        "\n",
        "    if not valid_files:\n",
        "        print(\"‚ùå No se encontraron archivos v√°lidos\")\n",
        "        return None\n",
        "\n",
        "    files_with_metrics = [f for f in valid_files if f['metrics'] is not None]\n",
        "    if files_with_metrics:\n",
        "        best_file = max(files_with_metrics, key=lambda x: x['metrics'])\n",
        "        print(f\"‚úÖ Seleccionado por mejores m√©tricas: {best_file['filename']} (m√©trica: {best_file['metrics']})\")\n",
        "    else:\n",
        "        best_file = max(valid_files, key=lambda x: x['mod_time'])\n",
        "        mod_time_str = pd.to_datetime(best_file['mod_time'], unit='s').strftime('%Y-%m-%d %H:%M')\n",
        "        print(f\"‚úÖ Seleccionado por fecha m√°s reciente: {best_file['filename']} ({mod_time_str})\")\n",
        "\n",
        "    return best_file['filename']\n",
        "\n",
        "def load_and_compare_all_params(json_files):\n",
        "    \"\"\"\n",
        "    Carga todos los archivos de par√°metros y selecciona el mejor basado en m√©tricas guardadas\n",
        "    \"\"\"\n",
        "    if not json_files:\n",
        "        print(\"‚ö†Ô∏è No se encontraron archivos de par√°metros\")\n",
        "        return None, None\n",
        "\n",
        "    print(f\"\\nüîÑ Analizando {len(json_files)} archivos de par√°metros...\")\n",
        "    best_params = None\n",
        "    best_file = None\n",
        "    best_score = -float('inf')\n",
        "    valid_files_count = 0\n",
        "\n",
        "    for filename in json_files:\n",
        "        try:\n",
        "            if not os.path.exists(filename) or os.path.getsize(filename) == 0:\n",
        "                print(f\"  ‚ö†Ô∏è Archivo vac√≠o o inexistente: {filename}\")\n",
        "                continue\n",
        "\n",
        "            with open(filename, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            if not data:\n",
        "                print(f\"  ‚ö†Ô∏è Archivo JSON vac√≠o: {filename}\")\n",
        "                continue\n",
        "\n",
        "            valid_files_count += 1\n",
        "\n",
        "            score = 0\n",
        "            score_source = \"timestamp\"\n",
        "\n",
        "            if 'metrics' in data and isinstance(data['metrics'], dict):\n",
        "                r2 = data['metrics'].get('r2', 0)\n",
        "                accuracy = data['metrics'].get('accuracy', 0)\n",
        "\n",
        "                if isinstance(r2, (int, float)) and isinstance(accuracy, (int, float)):\n",
        "                    score = r2 * 0.6 + accuracy * 0.4\n",
        "                    score_source = f\"m√©tricas (R2:{r2:.3f}, Acc:{accuracy:.3f})\"\n",
        "                else:\n",
        "                    score = os.path.getmtime(filename)\n",
        "                    score_source = \"timestamp (m√©tricas inv√°lidas)\"\n",
        "\n",
        "            elif 'best_value' in data and isinstance(data['best_value'], (int, float)):\n",
        "                score = -data['best_value']\n",
        "                score_source = f\"Optuna best_value ({data['best_value']})\"\n",
        "            else:\n",
        "                score = os.path.getmtime(filename)\n",
        "                score_source = \"timestamp (fallback)\"\n",
        "\n",
        "            print(f\"  üìä {filename}: score={score:.4f} ({score_source})\")\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                if 'best_params' in data:\n",
        "                    best_params = data['best_params']\n",
        "                elif 'model_params' in data:\n",
        "                    best_params = data['model_params']\n",
        "                else:\n",
        "                    best_params = data\n",
        "                best_file = filename\n",
        "\n",
        "        except json.JSONDecodeError as e:\n",
        "            print(f\"  ‚ùå Error JSON en {filename}: {e}\")\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Error cargando {filename}: {e}\")\n",
        "\n",
        "    if best_file and best_params:\n",
        "        print(f\"‚úÖ Mejor archivo seleccionado: {best_file} (score: {best_score:.4f})\")\n",
        "        print(f\"üìã Par√°metros cargados: {len(best_params)} elementos\")\n",
        "    else:\n",
        "        print(\"‚ùå No se pudo seleccionar ning√∫n archivo v√°lido\")\n",
        "\n",
        "    return best_file, best_params\n",
        "\n",
        "def save_metrics_with_timestamp(metrics_data, prefix=\"metrics\", include_score=True):\n",
        "    \"\"\"\n",
        "    Guarda las m√©tricas en un archivo JSON con timestamp\n",
        "    \"\"\"\n",
        "    try:\n",
        "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "        filename = f\"{prefix}_{timestamp}\"\n",
        "\n",
        "        if include_score and 'metrics' in metrics_data:\n",
        "            metrics = metrics_data['metrics']\n",
        "            if 'r2' in metrics and 'accuracy' in metrics:\n",
        "                r2 = metrics['r2']\n",
        "                accuracy = metrics['accuracy']\n",
        "                score = r2 * 0.6 + accuracy * 0.4\n",
        "                filename += f\"_score_{score:.4f}\"\n",
        "\n",
        "        filename += \".json\"\n",
        "\n",
        "        with open(filename, 'w', encoding='utf-8') as f:\n",
        "            json.dump(metrics_data, f, indent=4, ensure_ascii=False)\n",
        "\n",
        "        print(f\"üíæ M√©tricas guardadas en: {filename}\")\n",
        "        return filename\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error guardando m√©tricas: {e}\")\n",
        "        return None\n",
        "\n",
        "def main_workflow():\n",
        "    \"\"\"\n",
        "    Workflow principal automatizado\n",
        "    \"\"\"\n",
        "    print(\"=\"*60)\n",
        "    print(\"üöÄ INICIANDO WORKFLOW AUTOMATIZADO DE OPTIMIZACI√ìN\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(\"\\nüìä Preparando datos...\")\n",
        "\n",
        "    if not os.path.exists(\"spill_data_cleaned.csv\"):\n",
        "        print(\"‚ùå No se encontr√≥ el archivo 'spill_data_cleaned.csv'\")\n",
        "        print(\"   Aseg√∫rate de que el archivo est√© en el directorio actual\")\n",
        "        return None, None\n",
        "\n",
        "    df = pd.read_csv(\"spill_data_cleaned.csv\", sep=';', encoding='latin-1')\n",
        "    df = df.dropna(subset=['release_prod_water_edit'])\n",
        "    df['log_release_prod_water_edit'] = np.log1p(df['release_prod_water_edit'])\n",
        "\n",
        "    cat_cols = ['operator_edit', 'county_edit', 'type_operation', 'source', 'probable_cause_edit']\n",
        "    for col in cat_cols:\n",
        "        df[col] = df[col].fillna('unknown')\n",
        "\n",
        "    df['date'] = pd.to_datetime(df['date_of_spill_edit'])\n",
        "    df['month'] = df['date'].dt.month\n",
        "    df['year'] = df['date'].dt.year\n",
        "    df.drop(columns=['date'], inplace=True)\n",
        "\n",
        "    y_reg = df['log_release_prod_water_edit']\n",
        "    y_clf = df['probable_cause_edit']\n",
        "    X = df[['year','month','operator_edit','county_edit','type_operation','source']]\n",
        "\n",
        "    num_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "    cat_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "    preprocessor = ColumnTransformer(transformers=[\n",
        "        ('num', StandardScaler(), num_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
        "    ])\n",
        "\n",
        "    X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "    le_causa = LabelEncoder()\n",
        "    y_clf_enc = le_causa.fit_transform(y_clf)\n",
        "    y_clf_oh = to_categorical(y_clf_enc)\n",
        "\n",
        "    X_train, X_test, y_reg_train, y_reg_test, y_clf_train, y_clf_test = train_test_split(\n",
        "        X_processed, y_reg, y_clf_oh, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    input_dim = X_train.shape[1]\n",
        "    num_classes = y_clf_oh.shape[1]\n",
        "\n",
        "    print(f\"‚úÖ Datos preparados: {X_train.shape[0]} muestras de entrenamiento\")\n",
        "\n",
        "    json_files = [f for f in os.listdir('.') if f.startswith('best_params_') and f.endswith('.json')]\n",
        "\n",
        "    if json_files:\n",
        "        print(f\"\\nüîç Archivos de par√°metros encontrados: {len(json_files)}\")\n",
        "        best_file, best_params = load_and_compare_all_params(json_files)\n",
        "\n",
        "        if best_params:\n",
        "            print(f\"‚úÖ Usando par√°metros del archivo: {best_file}\")\n",
        "            print(\"‚ö†Ô∏è Necesitas implementar build_model_from_params()\")\n",
        "        else:\n",
        "            print(\"‚ùå Error cargando par√°metros, necesitas ejecutar optimizaci√≥n...\")\n",
        "            print(\"‚ö†Ô∏è Necesitas implementar run_optuna_optimization()\")\n",
        "    else:\n",
        "        print(\"\\nüÜï No se encontraron archivos de par√°metros - ejecutando optimizaci√≥n inicial...\")\n",
        "        print(\"‚ö†Ô∏è Necesitas implementar run_optuna_optimization()\")\n",
        "\n",
        "    print(\"\\nüéØ Simulando entrenamiento y evaluaci√≥n...\")\n",
        "\n",
        "    r2 = 0.85\n",
        "    mse = 0.25\n",
        "    mae = 0.15\n",
        "    accuracy = 0.78\n",
        "\n",
        "    print(f\"üìä M√©tricas simuladas:\")\n",
        "    print(f\"   R¬≤ Score: {r2:.4f}\")\n",
        "    print(f\"   MSE: {mse:.4f}\")\n",
        "    print(f\"   MAE: {mae:.4f}\")\n",
        "    print(f\"   Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    metrics_summary = {\n",
        "        \"timestamp\": pd.Timestamp.now().isoformat(),\n",
        "        \"metrics\": {\n",
        "            \"r2\": r2,\n",
        "            \"mse\": mse,\n",
        "            \"mae\": mae,\n",
        "            \"accuracy\": accuracy\n",
        "        },\n",
        "        \"model_params\": best_params if 'best_params' in locals() else {},\n",
        "        \"training_epochs\": 93,\n",
        "        \"dataset_info\": {\n",
        "            \"train_samples\": X_train.shape[0],\n",
        "            \"test_samples\": X_test.shape[0],\n",
        "            \"features\": X_train.shape[1],\n",
        "            \"classes\": num_classes\n",
        "        }\n",
        "    }\n",
        "\n",
        "    local_filename = save_metrics_with_timestamp(metrics_summary, \"best_params\", True)\n",
        "\n",
        "    if local_filename:\n",
        "        print(f\"üíæ M√©tricas guardadas localmente en: {local_filename}\")\n",
        "\n",
        "    print(\"\\nüéâ Workflow completado!\")\n",
        "    print(\"\\nüìã Pr√≥ximos pasos:\")\n",
        "    print(\"   1. Integra tus funciones build_model_from_params() y run_optuna_optimization()\")\n",
        "    print(\"   2. Reemplaza las m√©tricas simuladas con las reales de tu modelo\")\n",
        "\n",
        "    return None, metrics_summary\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üîß Ejecutando workflow de optimizaci√≥n...\")\n",
        "\n",
        "    required_files = [\"spill_data_cleaned.csv\"]\n",
        "    missing_files = [f for f in required_files if not os.path.exists(f)]\n",
        "\n",
        "    if missing_files:\n",
        "        print(f\"‚ùå Archivos faltantes: {missing_files}\")\n",
        "        print(\"   Aseg√∫rate de tener todos los archivos necesarios en el directorio\")\n",
        "    else:\n",
        "        model, metrics = main_workflow()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def select_best_params_file(json_files):\n",
        "    \"\"\"\n",
        "    Selecciona autom√°ticamente el mejor archivo de par√°metros basado en:\n",
        "    1. Fecha de modificaci√≥n m√°s reciente\n",
        "    2. Si hay archivos con m√©tricas en el nombre, usa el de mejores m√©tricas\n",
        "    \"\"\"\n",
        "    if not json_files:\n",
        "        return None\n",
        "\n",
        "    print(f\"üîç Se encontraron {len(json_files)} archivos de par√°metros:\")\n",
        "\n",
        "    # Mostrar archivos disponibles\n",
        "    files_with_info = []\n",
        "    for f in json_files:\n",
        "        try:\n",
        "            # Obtener informaci√≥n del archivo\n",
        "            creation_time = os.path.getctime(f)\n",
        "            modification_time = os.path.getmtime(f)\n",
        "\n",
        "            # Intentar extraer m√©tricas del nombre del archivo si las tiene\n",
        "            metrics_in_name = None\n",
        "            if 'r2_' in f.lower() or 'acc_' in f.lower():\n",
        "                # Extraer valores num√©ricos del nombre\n",
        "                import re\n",
        "                numbers = re.findall(r'[\\d.]+', f)\n",
        "                if numbers:\n",
        "                    metrics_in_name = float(numbers[0])\n",
        "\n",
        "            files_with_info.append({\n",
        "                'filename': f,\n",
        "                'mod_time': modification_time,\n",
        "                'metrics': metrics_in_name\n",
        "            })\n",
        "\n",
        "            print(f\"  üìÑ {f} (modificado: {pd.to_datetime(modification_time, unit='s').strftime('%Y-%m-%d %H:%M')})\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ö†Ô∏è  Error leyendo {f}: {e}\")\n",
        "            files_with_info.append({\n",
        "                'filename': f,\n",
        "                'mod_time': 0,\n",
        "                'metrics': None\n",
        "            })\n",
        "\n",
        "    # Estrategia de selecci√≥n:\n",
        "    # 1. Si hay archivos con m√©tricas en el nombre, usar el de mejor m√©trica\n",
        "    # 2. Si no, usar el m√°s reciente\n",
        "\n",
        "    files_with_metrics = [f for f in files_with_info if f['metrics'] is not None]\n",
        "\n",
        "    if files_with_metrics:\n",
        "        # Usar el archivo con mejores m√©tricas (asumiendo que valores m√°s altos son mejores)\n",
        "        best_file = max(files_with_metrics, key=lambda x: x['metrics'])\n",
        "        print(f\"‚úÖ Seleccionado por mejores m√©tricas: {best_file['filename']} (m√©trica: {best_file['metrics']})\")\n",
        "    else:\n",
        "        # Usar el m√°s reciente\n",
        "        best_file = max(files_with_info, key=lambda x: x['mod_time'])\n",
        "        print(f\"‚úÖ Seleccionado por fecha m√°s reciente: {best_file['filename']}\")\n",
        "\n",
        "    return best_file['filename']\n",
        "\n",
        "def load_and_compare_all_params(json_files):\n",
        "    \"\"\"\n",
        "    Carga todos los archivos de par√°metros y selecciona el mejor basado en m√©tricas guardadas\n",
        "    \"\"\"\n",
        "    if not json_files:\n",
        "        return None, None\n",
        "\n",
        "    print(f\"\\nüîÑ Analizando {len(json_files)} archivos de par√°metros...\")\n",
        "\n",
        "    best_params = None\n",
        "    best_file = None\n",
        "    best_score = -float('inf')\n",
        "\n",
        "    for filename in json_files:\n",
        "        try:\n",
        "            with open(filename, 'r') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "            # Buscar m√©tricas de evaluaci√≥n en el archivo\n",
        "            score = 0\n",
        "            if 'metrics' in data:\n",
        "                # Si hay m√©tricas guardadas, usar R2 + Accuracy como score combinado\n",
        "                r2 = data['metrics'].get('r2', 0)\n",
        "                accuracy = data['metrics'].get('accuracy', 0)\n",
        "                score = r2 * 0.6 + accuracy * 0.4  # Peso 60% R2, 40% Accuracy\n",
        "            elif 'best_value' in data:\n",
        "                # Si hay best_value de Optuna\n",
        "                score = -data['best_value']  # Negativo porque Optuna minimiza\n",
        "            else:\n",
        "                # Usar timestamp como fallback\n",
        "                score = os.path.getmtime(filename)\n",
        "\n",
        "            print(f\"  üìä {filename}: score={score:.4f}\")\n",
        "\n",
        "            if score > best_score:\n",
        "                best_score = score\n",
        "                best_params = data.get('best_params', data)\n",
        "                best_file = filename\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"  ‚ùå Error cargando {filename}: {e}\")\n",
        "\n",
        "    if best_file:\n",
        "        print(f\"‚úÖ Mejor archivo seleccionado: {best_file} (score: {best_score:.4f})\")\n",
        "\n",
        "    return best_file, best_params\n",
        "\n",
        "def main_workflow():\n",
        "    \"\"\"\n",
        "    Workflow principal automatizado - sin preguntas interactivas\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"=\"*60)\n",
        "    print(\"üöÄ INICIANDO WORKFLOW AUTOMATIZADO DE OPTIMIZACI√ìN\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    # Cargar y preparar datos (tu c√≥digo existente)\n",
        "    print(\"\\nüìä Preparando datos...\")\n",
        "    df = pd.read_csv(\"spill_data_cleaned.csv\", sep=';', encoding='latin-1')\n",
        "    df = df.dropna(subset=['release_prod_water_edit'])\n",
        "    df['log_release_prod_water_edit'] = np.log1p(df['release_prod_water_edit'])\n",
        "\n",
        "    # Preparar caracter√≠sticas\n",
        "    cat_cols = ['operator_edit', 'county_edit', 'type_operation', 'source', 'probable_cause_edit']\n",
        "    for col in cat_cols:\n",
        "        df[col] = df[col].fillna('unknown')\n",
        "\n",
        "    df['date'] = pd.to_datetime(df['date_of_spill_edit'])\n",
        "    df['month'] = df['date'].dt.month\n",
        "    df['year'] = df['date'].dt.year\n",
        "    df.drop(columns=['date'], inplace=True)\n",
        "\n",
        "    y_reg = df['log_release_prod_water_edit']\n",
        "    y_clf = df['probable_cause_edit']\n",
        "    X = df[['year','month','operator_edit','county_edit','type_operation','source']]\n",
        "\n",
        "    # Preprocesamiento\n",
        "    num_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
        "    cat_features = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "    preprocessor = ColumnTransformer(transformers=[\n",
        "        ('num', StandardScaler(), num_features),\n",
        "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_features)\n",
        "    ])\n",
        "\n",
        "    X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "    le_causa = LabelEncoder()\n",
        "    y_clf_enc = le_causa.fit_transform(y_clf)\n",
        "    y_clf_oh = to_categorical(y_clf_enc)\n",
        "\n",
        "    X_train, X_test, y_reg_train, y_reg_test, y_clf_train, y_clf_test = train_test_split(\n",
        "        X_processed, y_reg, y_clf_oh, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    input_dim = X_train.shape[1]\n",
        "    num_classes = y_clf_oh.shape[1]\n",
        "    joblib.dump(le_causa, 'labelencoder_causa.pkl')\n",
        "    print(\"LabelEncoder guardado\")\n",
        "    print(f\"‚úÖ Datos preparados: {X_train.shape[0]} muestras de entrenamiento\")\n",
        "\n",
        "    # AUTOMATIZACI√ìN: Buscar y seleccionar autom√°ticamente el mejor archivo\n",
        "    json_files = [f for f in os.listdir('.') if f.startswith('best_params_') and f.endswith('.json')]\n",
        "\n",
        "    if json_files:\n",
        "        print(f\"\\nüîç Archivos de par√°metros encontrados: {len(json_files)}\")\n",
        "\n",
        "        # ESTRATEGIA 1: Comparar todos los archivos y usar el mejor\n",
        "        best_file, best_params = load_and_compare_all_params(json_files)\n",
        "\n",
        "        if best_params:\n",
        "            print(f\"‚úÖ Usando par√°metros del archivo: {best_file}\")\n",
        "            model = build_model_from_params(best_params, input_dim, num_classes)\n",
        "        else:\n",
        "            print(\"‚ùå Error cargando par√°metros, ejecutando nueva optimizaci√≥n...\")\n",
        "            json_filename, best_params = run_optuna_optimization(X_train, y_reg_train, y_clf_train, n_trials=150)\n",
        "            model = build_model_from_params(best_params, input_dim, num_classes)\n",
        "    else:\n",
        "        # PRIMERA VEZ: EJECUTAR OPTIMIZACI√ìN\n",
        "        print(\"\\nüÜï No se encontraron archivos de par√°metros - ejecutando optimizaci√≥n inicial...\")\n",
        "        json_filename, best_params = run_optuna_optimization(X_train, y_reg_train, y_clf_train, n_trials=150)\n",
        "        model = build_model_from_params(best_params, input_dim, num_classes)\n",
        "\n",
        "    print(\"\\nüèãÔ∏è Entrenando modelo final...\")\n",
        "\n",
        "    batch_size = best_params.get('batch_size', 64)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train,\n",
        "        {'regression': y_reg_train, 'classification': y_clf_train},\n",
        "        validation_split=0.2,\n",
        "        epochs=93,\n",
        "        batch_size=batch_size,\n",
        "        callbacks=[\n",
        "            EarlyStopping(patience=10, restore_best_weights=True),\n",
        "            ReduceLROnPlateau(patience=5, factor=0.5)\n",
        "        ],\n",
        "        verbose=1\n",
        "    )\n",
        "    # Guardar el modelo entrenado a disco justo aqu√≠:\n",
        "    model.save(\"modelo_trained.h5\")\n",
        "    print(\"Modelo guardado en modelo_trained.h5\")\n",
        "    joblib.dump(preprocessor, 'preprocessor.pkl')\n",
        "    print(\"Preprocessor guardado en preprocessor.pkl\")\n",
        "    print(\"\\nüî¨ Evaluando modelo...\")\n",
        "\n",
        "    test_results = model.evaluate(\n",
        "        X_test,\n",
        "        {'regression': y_reg_test, 'classification': y_clf_test},\n",
        "        verbose=0\n",
        "    )\n",
        "\n",
        "    predictions = model.predict(X_test, verbose=0)\n",
        "    y_reg_pred = predictions[0].flatten()\n",
        "    y_clf_pred = predictions[1]\n",
        "\n",
        "    r2 = r2_score(y_reg_test, y_reg_pred)\n",
        "    mse = mean_squared_error(y_reg_test, y_reg_pred)\n",
        "    mae = np.mean(np.abs(y_reg_test - y_reg_pred))\n",
        "\n",
        "    y_clf_pred_classes = np.argmax(y_clf_pred, axis=1)\n",
        "    y_clf_test_classes = np.argmax(y_clf_test, axis=1)\n",
        "    accuracy = accuracy_score(y_clf_test_classes, y_clf_pred_classes)\n",
        "    \n",
        "    # === NUEVAS SECCIONES: TABLAS PARA TODAS LAS M√âTRICAS ===\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"üìä TABLAS DETALLADAS DE M√âTRICAS POR √âPOCA\")\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    # Obtener todas las m√©tricas del historial\n",
        "    epochs_range = range(1, len(history.history['loss']) + 1)\n",
        "\n",
        "    # Funci√≥n auxiliar para mostrar tabla\n",
        "    def show_metric_table(title, train_metric, val_metric, metric_name, show_diff=True):\n",
        "        print(f\"\\n{title}\")\n",
        "        print(\"-\" * 80)\n",
        "        if show_diff:\n",
        "            print(f\"{'Epoch':<8} {'Train '+metric_name:<15} {'Val '+metric_name:<15} {'Diferencia':<15}\")\n",
        "        else:\n",
        "            print(f\"{'Epoch':<8} {'Train '+metric_name:<15} {'Val '+metric_name:<15}\")\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        for i in range(0, len(train_metric), 5):\n",
        "            epoch = i + 1\n",
        "            train_val = train_metric[i]\n",
        "            val_val = val_metric[i]\n",
        "            if show_diff:\n",
        "                diff = abs(train_val - val_val)\n",
        "                print(f\"{epoch:<8} {train_val:<15.4f} {val_val:<15.4f} {diff:<15.4f}\")\n",
        "            else:\n",
        "                print(f\"{epoch:<8} {train_val:<15.4f} {val_val:<15.4f}\")\n",
        "\n",
        "        # Mostrar √∫ltima √©poca si no se mostr√≥\n",
        "        if (len(train_metric) - 1) % 5 != 0:\n",
        "            i = len(train_metric) - 1\n",
        "            epoch = i + 1\n",
        "            train_val = train_metric[i]\n",
        "            val_val = val_metric[i]\n",
        "            if show_diff:\n",
        "                diff = abs(train_val - val_val)\n",
        "                print(f\"{epoch:<8} {train_val:<15.4f} {val_val:<15.4f} {diff:<15.4f}\")\n",
        "            else:\n",
        "                print(f\"{epoch:<8} {train_val:<15.4f} {val_val:<15.4f}\")\n",
        "\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "        # Estad√≠sticas de resumen\n",
        "        best_train = max(train_metric) if 'acc' in metric_name.lower() else min(train_metric)\n",
        "        best_val = max(val_metric) if 'acc' in metric_name.lower() else min(val_metric)\n",
        "        best_train_epoch = (train_metric.index(best_train) + 1) if 'acc' in metric_name.lower() else (train_metric.index(best_train) + 1)\n",
        "        best_val_epoch = (val_metric.index(best_val) + 1) if 'acc' in metric_name.lower() else (val_metric.index(best_val) + 1)\n",
        "\n",
        "        comparison = \"Mejor\" if 'acc' in metric_name.lower() else \"Menor\"\n",
        "        print(f\"\\nRESUMEN {metric_name.upper()}:\")\n",
        "        print(f\"{comparison} Train: {best_train:.4f} (√âpoca {best_train_epoch})\")\n",
        "        print(f\"{comparison} Val:   {best_val:.4f} (√âpoca {best_val_epoch})\")\n",
        "        print(f\"Final Train: {train_metric[-1]:.4f}\")\n",
        "        print(f\"Final Val:   {val_metric[-1]:.4f}\")\n",
        "\n",
        "    # 1. TABLA DE P√âRDIDA TOTAL\n",
        "    train_loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    show_metric_table(\"1. P√âRDIDA TOTAL vs √âPOCAS\", train_loss, val_loss, \"Loss\")\n",
        "\n",
        "    # 2. TABLA DE ACCURACY\n",
        "    train_acc = history.history['classification_accuracy']\n",
        "    val_acc = history.history['val_classification_accuracy']\n",
        "    show_metric_table(\"2. ACCURACY vs √âPOCAS\", train_acc, val_acc, \"Accuracy\")\n",
        "    print(f\"Accuracy en Test: {accuracy:.4f}\")\n",
        "\n",
        "    # 3. TABLA DE MAE REGRESI√ìN\n",
        "    train_mae = history.history['regression_mae']\n",
        "    val_mae = history.history['val_regression_mae']\n",
        "    show_metric_table(\"3. MAE REGRESI√ìN vs √âPOCAS\", train_mae, val_mae, \"MAE\")\n",
        "    print(f\"MAE en Test: {mae:.4f}\")\n",
        "\n",
        "    # 4. TABLA DE P√âRDIDA CLASIFICACI√ìN\n",
        "    train_cls_loss = history.history['classification_loss']\n",
        "    val_cls_loss = history.history['val_classification_loss']\n",
        "    show_metric_table(\"4. P√âRDIDA CLASIFICACI√ìN vs √âPOCAS\", train_cls_loss, val_cls_loss, \"Cls_Loss\")\n",
        "\n",
        "    # 5. TABLA DE P√âRDIDA REGRESI√ìN\n",
        "    train_reg_loss = history.history['regression_loss']\n",
        "    val_reg_loss = history.history['val_regression_loss']\n",
        "    show_metric_table(\"5. P√âRDIDA REGRESI√ìN vs √âPOCAS\", train_reg_loss, val_reg_loss, \"Reg_Loss\")\n",
        "\n",
        "    # 6. TABLA CONSOLIDADA (RESUMEN)\n",
        "    print(\"\\n\" + \"=\"*100)\n",
        "    print(\"6. TABLA CONSOLIDADA - TODAS LAS M√âTRICAS (cada 10 √©pocas)\")\n",
        "    print(\"=\"*100)\n",
        "    print(f\"{'Epoch':<8} {'Total_Loss':<12} {'Accuracy':<12} {'Reg_MAE':<12} {'Cls_Loss':<12} {'Reg_Loss':<12}\")\n",
        "    print(f\"{'':<8} {'T/V':<12} {'T/V':<12} {'T/V':<12} {'T/V':<12} {'T/V':<12}\")\n",
        "    print(\"-\" * 100)\n",
        "\n",
        "    for i in range(0, len(train_loss), 10):\n",
        "        epoch = i + 1\n",
        "        print(f\"{epoch:<8} {train_loss[i]:<5.3f}/{val_loss[i]:<5.3f} {train_acc[i]:<5.3f}/{val_acc[i]:<5.3f} {train_mae[i]:<5.3f}/{val_mae[i]:<5.3f} {train_cls_loss[i]:<5.3f}/{val_cls_loss[i]:<5.3f} {train_reg_loss[i]:<5.3f}/{val_reg_loss[i]:<5.3f}\")\n",
        "\n",
        "    # Mostrar √∫ltima √©poca en tabla consolidada\n",
        "    if (len(train_loss) - 1) % 10 != 0:\n",
        "        i = len(train_loss) - 1\n",
        "        epoch = i + 1\n",
        "        print(f\"{epoch:<8} {train_loss[i]:<5.3f}/{val_loss[i]:<5.3f} {train_acc[i]:<5.3f}/{val_acc[i]:<5.3f} {train_mae[i]:<5.3f}/{val_mae[i]:<5.3f} {train_cls_loss[i]:<5.3f}/{val_cls_loss[i]:<5.3f} {train_reg_loss[i]:<5.3f}/{val_reg_loss[i]:<5.3f}\")\n",
        "\n",
        "    print(\"-\" * 100)\n",
        "    print(\"T = Training, V = Validation\")\n",
        "    \n",
        "\n",
        "    # === FIN DE NUEVAS SECCIONES ===\n",
        "\n",
        "    # Visualizaci√≥n (mantener las existentes)\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.boxplot(df['log_release_prod_water_edit'].dropna())\n",
        "    plt.title('Boxplot of Logarithm of release_prod_water_edit')\n",
        "    plt.ylabel('Log(release_prod_water_edit)')\n",
        "    plt.grid(True)\n",
        "    print(\"Boxplot mostrado en pantalla\")\n",
        "    plt.show()\n",
        "\n",
        "    # Gr√°ficos existentes + nuevo gr√°fico de accuracy\n",
        "    plt.figure(figsize=(16, 8))  # Aumentar tama√±o para acomodar 4 subplots\n",
        "\n",
        "    plt.subplot(2, 3, 1)\n",
        "    plt.plot(history.history['loss'], label='Training')\n",
        "    plt.plot(history.history['val_loss'], label='Validation')\n",
        "    plt.title('P√©rdida Total')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(2, 3, 2)\n",
        "    plt.plot(history.history['regression_mae'], label='Training')\n",
        "    plt.plot(history.history['val_regression_mae'], label='Validation')\n",
        "    plt.title('MAE Regresi√≥n')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(2, 3, 3)\n",
        "    plt.scatter(y_reg_test, y_reg_pred, alpha=0.6)\n",
        "    plt.plot([y_reg_test.min(), y_reg_test.max()], [y_reg_test.min(), y_reg_test.max()], 'r--')\n",
        "    plt.xlabel('Real')\n",
        "    plt.ylabel('Predicho')\n",
        "    plt.title(f'Regresi√≥n (R¬≤={r2:.3f})')\n",
        "\n",
        "    # NUEVO: Gr√°fico de Accuracy vs Epochs\n",
        "    plt.subplot(2, 3, 4)\n",
        "    epochs_range = range(1, len(history.history['classification_accuracy']) + 1)\n",
        "    train_acc = history.history['classification_accuracy']\n",
        "    val_acc = history.history['val_classification_accuracy']\n",
        "    plt.plot(epochs_range, train_acc, label='Training', marker='o', markersize=2)\n",
        "    plt.plot(epochs_range, val_acc, label='Validation', marker='s', markersize=2)\n",
        "    plt.xlabel('√âpoca')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.title('Accuracy vs √âpocas')\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "\n",
        "    plt.subplot(2, 3, 5)\n",
        "    plt.plot(history.history['classification_loss'], label='Training')\n",
        "    plt.plot(history.history['val_classification_loss'], label='Validation')\n",
        "    plt.title('P√©rdida Clasificaci√≥n')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(2, 3, 6)\n",
        "    plt.plot(history.history['regression_loss'], label='Training')\n",
        "    plt.plot(history.history['val_regression_loss'], label='Validation')\n",
        "    plt.title('P√©rdida Regresi√≥n')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    print(\"Gr√°fico de m√©tricas\")\n",
        "    plt.show()\n",
        "\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"RESULTADOS FINALES\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"Regresi√≥n:\")\n",
        "    print(f\"  R¬≤ Score: {r2:.4f}\")\n",
        "    print(f\"  MSE: {mse:.4f}\")\n",
        "    print(f\"  MAE: {mae:.4f}\")\n",
        "    print(f\"\\nClasificaci√≥n:\")\n",
        "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    # === GUARDAR M√âTRICAS EN JSON CON TIMESTAMP ===\n",
        "    metrics_summary = {\n",
        "        \"timestamp\": pd.Timestamp.now().isoformat(),\n",
        "        \"metrics\": {\n",
        "            \"r2\": r2,\n",
        "            \"mse\": mse,\n",
        "            \"mae\": mae,\n",
        "            \"accuracy\": accuracy\n",
        "        },\n",
        "        \"model_params\": best_params,\n",
        "        \"training_epochs\": len(history.history['loss']),\n",
        "        \"final_training_loss\": float(history.history['loss'][-1]),\n",
        "        \"final_validation_loss\": float(history.history['val_loss'][-1])\n",
        "    }\n",
        "\n",
        "    print(\"\\nResumen final de m√©tricas:\")\n",
        "    print(json.dumps(metrics_summary, indent=4))\n",
        "\n",
        "    # === MOSTRAR PREDICCIONES EN PANTALLA (no guardar) ===\n",
        "    reg_pred_original = np.expm1(y_reg_pred)\n",
        "\n",
        "    df_preds = pd.DataFrame({\n",
        "        'y_reg_real': np.expm1(y_reg_test.values),\n",
        "        'y_reg_pred': reg_pred_original,\n",
        "        'y_clf_real': le_causa.inverse_transform(y_clf_test_classes),\n",
        "        'y_clf_pred': le_causa.inverse_transform(y_clf_pred_classes)\n",
        "    })\n",
        "\n",
        "    print(\"\\nEjemplo de predicciones:\")\n",
        "    print(df_preds.head())\n",
        "\n",
        "    # === GUARDAR PAR√ÅMETROS ACTUALIZADOS SI SE MEJOR√ì ===\n",
        "    if 'best_file' in locals() and best_file:\n",
        "        # Comparar m√©tricas actuales con las del archivo usado\n",
        "        try:\n",
        "            with open(best_file, 'r') as f:\n",
        "                old_data = json.load(f)\n",
        "\n",
        "            old_r2 = old_data.get('metrics', {}).get('r2', 0)\n",
        "            old_acc = old_data.get('metrics', {}).get('accuracy', 0)\n",
        "            old_score = old_r2 * 0.6 + old_acc * 0.4\n",
        "\n",
        "            current_score = r2 * 0.6 + accuracy * 0.4\n",
        "\n",
        "            if current_score > old_score:\n",
        "                new_filename = f\"best_params_improved_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "                with open(new_filename, 'w') as f:\n",
        "                    json.dump(metrics_summary, f, indent=4)\n",
        "                print(f\"‚úÖ M√©tricas mejoradas! Guardado nuevo archivo: {new_filename}\")\n",
        "                print(f\"   Score anterior: {old_score:.4f} ‚Üí Score actual: {current_score:.4f}\")\n",
        "            else:\n",
        "                print(f\"üìä M√©tricas actuales ({current_score:.4f}) no superaron las del archivo usado ({old_score:.4f})\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è  Error comparando m√©tricas: {e}\")\n",
        "\n",
        "    print(\"\\nüéâ Workflow completado autom√°ticamente!\")\n",
        "\n",
        "    return model, best_params\n",
        "\n",
        "# Ejecutar workflow\n",
        "main_workflow()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Carga del CSV con separador y codificaci√≥n espec√≠fica\n",
        "df = pd.read_csv('spill_data_cleaned.csv', sep=';', encoding='latin1')\n",
        "\n",
        "# Lista de columnas de inter√©s\n",
        "columnas = ['operator_edit', 'county_edit', 'type_operation', 'source']\n",
        "\n",
        "# Mostrar valores √∫nicos para cada columna\n",
        "for col in columnas:\n",
        "    print(f\"\\nValores √∫nicos de '{col}':\")\n",
        "    print(df[col].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Valores √∫nicos de 'county_edit':\")\n",
        "print(df['county_edit'].dropna().unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nValores √∫nicos de 'type_operation':\")\n",
        "print(df['type_operation'].dropna().unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\nValores √∫nicos de 'source':\")\n",
        "print(df['source'].dropna().unique())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
